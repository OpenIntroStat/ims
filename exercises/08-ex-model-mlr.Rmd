1. **High correlation, good or bad?**
Two friends, Frances and Annika, are in disagreement about whether high correlation values are *always* good in the context of regression.
Frances claims that it's desirable for all variables in the dataset to be highly correlated to each other when building linear models.
Annika claims that while it's desirable for each of the predictors to be highly correlated with the outcome, it is not desirable for the predictors to be highly correlated with each other.
Who is right: Frances, Annika, both, or neither? 
Explain your reasoning using appropriate terminology.

1. **Dealing with categorical predictors.**
Two friends, Elliott and Adrian, want to build a model predicting typing speed (average number of words typed per minute) from whether the person wears glasses or not.
Before building the model they want to conduct some exploratory analysis to evaluate the strength of the association between these two variables, but they're in disagreement about how to evaluate how strongly a categorical predictor is associated with a numerical outcome.
Elliott claims that it is not possible to calculate a correlation coefficient to summarize the relationship between a categorical predictor and a numerical outcome, however they're not sure what a better alternative is.
Adrian claims that you can recode a binary predictor as a 0/1 variable (assign one level to be 0 and the other to be 1), thus converting it to a numerical variable.
According to Adrian, you can then calculate the correlation coefficient between the predictor and the outcome.
Who is right: Elliott or Adrian?
If you pick Elliott, can you suggest a better alternative for evaluating the association between the categorical predictor and the numerical outcome?

1. **Training for the 5K.**
Nico signs up for a 5K (a 5,000 metre running race) 30 days prior to the race. 
They decide to run a 5K every day to train for it, and each day they record the following information: `days_since_start` (number of days since starting training), `days_till_race` (number of days left until the race), `mood` (poor, good, awesome), `tiredness` (1-not tired to 10-very tired), and `time` (time it takes to run 5K, recorded as mm:ss).
Top few rows of the data they collect is shown below.

    ```{r}
    library(tidyverse)
    tribble(
      ~days_since_start, ~days_till_race, ~mood, ~tiredness, ~time,
      "1", "29", "good", "3", "25:45",
      "2", "28", "poor", "5", "27:13",
      "3", "27", "awesome", "4", "24:13",
      "...", "...", "...", "...", "..."
    ) %>%
      kbl(linesep = "", booktabs = TRUE, align = "rrlrr") %>%
      kable_styling(bootstrap_options = c("striped", "condensed"), 
                    latex_options = "HOLD_position", 
                    full_width = FALSE)
    ```
    
    Using these data Nico wants to build a model predicting `time` from the other variables. Should they include all variables shown above in their model? Why or why not?

1. **Multiple regression fact checking.**
Determine which of the following statements are true and false.
For each statement that is false, explain why it is false.

    a. If predictors are collinear, then removing one variable will have no influence on the point estimate of another variable's coefficient.

    b. Suppose a numerical variable $x$ has a coefficient of $b_1 = 2.5$ in the multiple regression model. Suppose also that the first observation has $x_1 = 7.2$, the second observation has a value of $x_1 = 8.2$, and these two observations have the same values for all other predictors. Then the predicted value of the second observation will be 2.5 higher than the prediction of the first observation based on the multiple regression model.

    c. If a regression model's first variable has a coefficient of $b_1 = 5.7$, then if we are able to influence the data so that an observation will have its $x_1$ be 1 larger than it would otherwise, the value $y_1$ for this observation would increase by 5.7.
    
    \clearpage

1. **Baby weights and smoking.** 
US Department of Health and Human Services, Centers for Disease Control and Prevention collect information on births recorded in the country.
The data used here are a random sample of 1,000 births from 2014.
Here, we study the relationship between smoking and weight of the baby. 
The variable `smoke` is coded 1 if the mother is a smoker, and 0 if not. 
The summary table below shows the results of a linear regression model for predicting the average birth weight of babies, measured in pounds, based on the smoking status of the mother.^[The [`births14`](http://openintrostat.github.io/openintro/reference/births14.html) data used in this exercise can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.] [@data:births14]

    ```{r}
    library(openintro)
    library(tidyverse)
    library(kableExtra)
    library(broom)

    m_habit_fage <- lm(weight ~ habit, data = births14)

    tidy(m_habit_fage) %>%
      mutate(p.value = ifelse(p.value < 0.0001, "<0.0001", round(p.value, 4))) %>%
      kbl(linesep = "", booktabs = TRUE, align = "lrrrr", digits = 4) %>%
      kable_styling(bootstrap_options = c("striped", "condensed"), 
                    latex_options = "HOLD_position",
                    full_width = FALSE) %>%
      column_spec(1, width = "10em", monospace = TRUE) %>%
      column_spec(2:5, width = "5em")
    ```

    a.  Write the equation of the regression model.

    b.  Interpret the slope in this context, and calculate the predicted birth weight of babies born to smoker and non-smoker mothers.

1. **Baby weights and mature moms.**
The following is a model for predicting baby weight from whether the mom is classified as a `mature` mom (35 years or older at the time of pregnancy). [@data:births14]

    ```{r}
    library(openintro)
    library(tidyverse)
    library(kableExtra)
    library(broom)

    m_weight_mature <- lm(weight ~ mature, data = births14)
    
    m_weight_mature %>%
      tidy() %>%
      mutate(p.value = ifelse(p.value < 0.0001, "<0.0001", round(p.value, 4))) %>%
      kbl(linesep = "", booktabs = TRUE, align = "lrrrr", digits = 4) %>%
      kable_styling(bootstrap_options = c("striped", "condensed"), 
                    latex_options = "HOLD_position",
                    full_width = FALSE) %>%
      column_spec(1, width = "10em", monospace = TRUE) %>%
      column_spec(2:5, width = "5em")
    ```

    a.  Write the equation of the regression model.

    b.  Interpret the slope in this context, and calculate the predicted birth weight of babies born to mature and younger mothers.
    
1. **Movie returns, prediction.**
A model was fit to predict return-on-investment (ROI) on movies based on release year and genre (Adventure, Action, Drama, Horror, and Comedy). The model output is shown below. [@webpage:horrormovies]

    ```{r}
    library(openintro)
    library(tidyverse)
    library(kableExtra)
    library(lubridate)
    library(broom)
    
    movie_profit <- read_csv("data/movie_profit.csv")
    movie_profit <- movie_profit %>%
      mutate(
        release_date = mdy(release_date),
        release_year = year(release_date),
        oct_release = ifelse(month(release_date) == 10, "yes", "no"),
        dom_gross_to_prod = domestic_gross / production_budget,
        ww_gross_to_prod = worldwide_gross / production_budget
        )%>%
      filter(
        release_year >= 2010,
        release_year < 2019
        )
    
    m_movie_small <- lm(ww_gross_to_prod ~ release_year + genre, data = movie_profit)
    m_movie_large <- lm(ww_gross_to_prod ~ release_year + genre + production_budget, data = movie_profit)
    
    m_movie_small_adj_rsq <- round(glance(m_movie_small)$adj.r.squared, 4)*100
    m_movie_large_adj_rsq <- round(glance(m_movie_large)$adj.r.squared, 4)*100
    
    m_movie_small %>%
      tidy() %>%
      mutate(p.value = ifelse(p.value < 0.0001, "<0.0001", round(p.value, 4))) %>%
      kbl(linesep = "", booktabs = TRUE, align = "lrrrr", digits = 2) %>%
      kable_styling(bootstrap_options = c("striped", "condensed"), 
                    latex_options = "HOLD_position",
                    full_width = FALSE) %>%
      column_spec(1, width = "10em", monospace = TRUE) %>%
      column_spec(2:5, width = "5em")
    ```
    
    a. For a given release year, which genre of movies are predicted, on average, to have the highest predicted return on investment?
    
    b. The adjusted $R^2$ of this model is `r m_movie_small_adj_rsq`%. Adding the production budget of the movie to the model increases the adjusted $R^2$ to `r m_movie_large_adj_rsq`%. Should production budget be added to the model?
    
    \clearpage

1. **Movie returns by genre.**
A model was fit to predict return-on-investment (ROI) on movies based on release year and genre (Adventure, Action, Drama, Horror, and Comedy). 
The plots below show the predicted ROI vs. actual ROI for each of the genres separately. Do these figures support the comment in the FiveThirtyEight.com article that states, "The return-on-investment potential for horror movies is absurd." Note that the x-axis range varies for each plot. [@webpage:horrormovies]

    ```{r}
    movie_profit <- read_csv("data/movie_profit.csv")
    movie_profit <- movie_profit %>%
      mutate(
        release_date = mdy(release_date),
        release_year = year(release_date),
        oct_release = ifelse(month(release_date) == 10, "yes", "no"),
        dom_gross_to_prod = domestic_gross / production_budget,
        ww_gross_to_prod = worldwide_gross / production_budget
        ) %>%
      filter(
        release_year >= 2010,
        release_year < 2019
        )
    
    m_movie <- lm(ww_gross_to_prod ~ release_year + genre, data = movie_profit)
    m_movie_aug <- augment(m_movie)
    
    ggplot(m_movie_aug, aes(y = .fitted, x = ww_gross_to_prod, color = genre)) + 
      geom_point(alpha = 0.5, show.legend = FALSE, size = 2) +
      facet_wrap(~genre, scales = "free_x") +
      theme_minimal() + 
      labs(x = "Actual ROI", y = "Predicted ROI", color = "Genre") +
      scale_color_openintro("five")
    ````

1. **Predicting baby weights.**
A more realistic approach to modeling baby weights is to consider all possibly related variables at once. Other variables of interest include length of pregnancy in weeks (`weeks`), mother's age in years (`mage`), the sex of the baby (`sex`), smoking status of the mother (`habit`), and the number of hospital (`visits`) visits during pregnancy. Below are three observations from this data set.

    ```{r}
    library(tidyverse)
    library(openintro)
    
    births14 %>%
      dplyr::select(weight, weeks, mage, sex, visits, habit) %>%
      slice_head(n = 3) %>%
      kbl(linesep = "", booktabs = TRUE, align = "ccccc") %>%
      kable_styling(bootstrap_options = c("striped", "condensed"), 
                    latex_options = "HOLD_position",
                    full_width = FALSE) %>%
      column_spec(1:5, width = "5em")
    ```

    The summary table below shows the results of a regression model for predicting the average birth weight of babies based on all of the variables presented above.
    
    ```{r}
    lm(weight ~ weeks + mage + sex + visits + habit, births14) %>%
      tidy() %>%
      mutate(p.value = ifelse(p.value < 0.0001, "<0.0001", round(p.value, 4))) %>%
      kbl(linesep = "", booktabs = TRUE, align = "lrrrr", digits = 2) %>%
      kable_styling(bootstrap_options = c("striped", "condensed"), 
                    latex_options = "HOLD_position",
                    full_width = FALSE) %>%
      column_spec(1, width = "10em", monospace = TRUE) %>%
      column_spec(2:5, width = "5em")
    ```

    a. Write the equation of the regression model that includes all of the variables.

    b. Interpret the slopes of `weeks` and `habit` in this context.

    c. If we fit a model predicting baby weight from only `habit` (whether the mom smokes), we observe a difference in the slope coefficient for `habit` in this small model and the slope coefficient for `habit` in the larger model. Why might there be a difference?

    d. Calculate the residual for the first observation in the data set.
    
    \clearpage

1. **Palmer penguins, predicting body mass.**
Researchers studying a community of Antarctic penguins collected body measurement (bill length, bill depth, and flipper length measured in millimeters and body mass, measured in grams), species (*Adelie*, *Chinstrap*, or *Gentoo*), and sex (female or male) data on 344 penguins living on three islands (Torgersen, Biscoe, and Dream) in the Palmer Archipelago, Antarctica.^[The [`penguins`](https://allisonhorst.github.io/palmerpenguins/reference/penguins.html) data used in this exercise can be found in the [**palmerpenguins**](https://allisonhorst.github.io/palmerpenguins/) R package.] The summary table below shows the results of a linear regression model for predicting body mass (which is more difficult to measure) from the other variables in the dataset. [@palmerpenguins] 
    
    ```{r}
    library(palmerpenguins)
    library(broom)
    library(kableExtra)
    library(tidyverse)
    
    m_full_penguins <- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + sex + species, data = penguins)
    
    m_full_penguins_rsq <- round(glance(m_full_penguins)$r.squared*100, 1)
    m_full_penguins_tidy <- tidy(m_full_penguins)
    
    m_full_penguins_tidy %>%
      mutate(
        p.value = ifelse(p.value < 0.0001, "<0.0001", round(p.value, 4)),
        ) %>%
      kbl(linesep = "", booktabs = TRUE, align = "lrrrr", digits = 1,
          format.args = list(scientific = FALSE)) %>%
      kable_styling(bootstrap_options = c("striped", "condensed"), 
                    latex_options = "HOLD_position", 
                    full_width = FALSE) %>%
      column_spec(1, width = "10em", monospace = TRUE) %>%
      column_spec(2:5, width = "5em")
    ```

    a.  Write the equation of the regression model.

    a.  Interpret each one of the slopes in this context.

    b.  Calculate the residual for a male Adelie penguin that weighs 3750 grams with the following body measurements: `bill_length_mm` = 39.1, `bill_depth_mm` = 18.7, `flipper_length_mm` = 181. Does the model overpredict or underpredict this penguin's weight?
    
    c.  The $R^2$ of this model is `r m_full_penguins_rsq`%. Interpret this value in context of the data and the model.
    
    \vspace{5mm}

1.  **Baby weights, backwards elimination.**
Let's consider a model that predicts `weight` of newborns using several predictors: whether the mother is considered `mature`, number of `weeks` of gestation, number of hospital `visits` during pregnancy, weight `gained` by the mother during pregnancy, `sex` of the baby, and whether the mother smoke cigarettes during pregnancy (`habit`). [@data:births14]

    ```{r}
    library(openintro)
    library(tidyverse)    
    library(kableExtra)
    library(broom)    
    
    m_full <- lm(weight ~ mature + weeks + gained + sex + habit, data = births14)
    m_full_adj_rsq <- round(glance(m_full)$adj.r.squared, 4)
    ```
    
    The adjusted $R^2$ of the full model is `r m_full_adj_rsq`.
    We remove each variable one by one, refit the model, and record the adjusted $R^2$.
    Which, if any, variable should be removed from the model?
    
    ```{r}
    m_m <- update(m_full, . ~ . - mature, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_w <- update(m_full, . ~ . - weeks, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_v <- update(m_full, . ~ . - visits, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_g <- update(m_full, . ~ . - gained, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_s <- update(m_full, . ~ . - sex, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    ```
    
    -  Drop `mature`:  `r m_m`
    -  Drop `weeks`:   `r m_w`
    -  Drop `visits`:  `r m_v`
    -  Drop `gained`:  `r m_g`
    -  Drop `sex`:     `r m_s`
    
    \clearpage

1. **Palmer penguins, backwards elimination.**
The following full model is built to predict the weights of three species (*Adelie*, *Chinstrap*, or *Gentoo*) of penguins living in the Palmer Archipelago, Antarctica. [@palmerpenguins]

    ```{r}
    library(palmerpenguins)
    library(broom)
    library(kableExtra)
    library(tidyverse)
    
    m_full_penguins <- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + sex + species, data = penguins)
    
    m_full_penguins_rsq_adj <- round(glance(m_full_penguins)$adj.r.squared, 1)
    m_full_penguins_tidy <- tidy(m_full_penguins)
    
    m_full_penguins_tidy %>%
      mutate(
        p.value = ifelse(p.value < 0.0001, "<0.0001", round(p.value, 4)),
        ) %>%
      kbl(linesep = "", booktabs = TRUE, align = "lrrrr", digits = 1,
          format.args = list(scientific = FALSE)) %>%
      kable_styling(bootstrap_options = c("striped", "condensed"), 
                    latex_options = "HOLD_position", 
                    full_width = FALSE) %>%
      column_spec(1, width = "10em", monospace = TRUE) %>%
      column_spec(2:5, width = "5em")
    ```
    
    The adjusted $R^2$ of the full model is `r m_full_penguins_rsq_adj`. In order to evaluate whether any of the predictors can be dropped from the model without losing predictive performance of the model, the researchers dropped one variable at a time, refit the model, and recorded the adjusted $R^2$ of the smaller model. These values are given below.
    
    ```{r}
    m_bl <- update(m_full_penguins, . ~ . - bill_length_mm, data = penguins) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_bd <- update(m_full_penguins, . ~ . - bill_depth_mm, data = penguins) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_fl <- update(m_full_penguins, . ~ . - flipper_length_mm, data = penguins) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_sex <- update(m_full_penguins, . ~ . - sex, data = penguins) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_sp <- update(m_full_penguins, . ~ . - species, data = penguins) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    ```
    
    -  Drop `bill_length_mm`:    `r m_bl`
    -  Drop `bill_depth_mm`:     `r m_bd`
    -  Drop `flipper_length_mm`: `r m_fl`
    -  Drop `sex`:               `r m_sex`
    -  Drop `species`:           `r m_sp`

    Which, if any, variable should be removed from the model first?

1.  **Baby weights, forward selection.**
Using information on the mother and the sex of the baby (which can be determined prior to birth), we want to build a model that predicts the birth weight of babies.
In order to do so, we will evaluate six candidate predictors: whether the mother is considered `mature`, number of `weeks` of gestation, number of hospital `visits` during pregnancy, weight `gained` by the mother during pregnancy, `sex` of the baby, and whether the mother smoke cigarettes during pregnancy (`habit`).
And we will make a decision about including them in the model using forward selection and adjusted $R^2$. 
Below are the six models we evaluate and their adjusted $R^2$ values. [@data:births14]

    ```{r}
    library(openintro)
    library(broom)
    library(kableExtra)
    library(tidyverse)
    
    m_mature  <- lm(weight ~ mature, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_weeks  <- lm(weight ~ weeks, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_visits  <- lm(weight ~ visits, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_gained <- lm(weight ~ gained, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_sex  <- lm(weight ~ sex, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_habit  <- lm(weight ~ habit, data = births14) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    ````
    -  Predict `weight` from `mature`: `r m_mature`
    -  Predict `weight` from `weeks`:  `r m_weeks`
    -  Predict `weight` from `visits`: `r m_visits`
    -  Predict `weight` from `gained`: `r m_gained`
    -  Predict `weight` from `sex`:    `r m_sex`
    -  Predict `weight` from `habit`:  `r m_habit`

    Which variable should be added to the model first?

1. **Palmer penguins, forward selection.**
Using body measurement and other relevant data on three species (*Adelie*, *Chinstrap*, or *Gentoo*) of penguins living in the Palmer Archipelago, Antarctica, we want to predict their body mass. In order to do so, we will evaluate five candidate predictors and make a decision about including them in the model using forward selection and adjusted $R^2$. Below are the five models we evaluate and their adjusted $R^2$ values:

    ```{r}
    library(palmerpenguins)
    library(broom)
    library(kableExtra)
    library(tidyverse)
    
    m_bl  <- lm(body_mass_g ~ bill_length_mm, data = penguins) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_bd  <- lm(body_mass_g ~ bill_depth_mm, data = penguins) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_fl  <- lm(body_mass_g ~ flipper_length_mm, data = penguins) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_sex <- lm(body_mass_g ~ sex, data = penguins) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    m_sp  <- lm(body_mass_g ~ species, data = penguins) %>%
      glance() %>%
      pull(adj.r.squared) %>%
      round(3)
    ````
    -  Predict body mass from `bill_length_mm`:    `r m_bl`
    -  Predict body mass from `bill_depth_mm`:     `r m_bd`
    -  Predict body mass from `flipper_length_mm`: `r m_fl`
    -  Predict body mass from `sex`:               `r m_sex`
    -  Predict body mass from `species`:           `r m_sp`

    Which variable should be added to the model first?
