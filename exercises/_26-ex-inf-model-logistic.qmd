1.  **Passing the driver's test.** A consulting company is hired to assess whether certain characteristics of a DMV (e.g., location, number of test takers, number of test givers, hours of operation, etc.) are associated with the pass rate of the driver's test.
    The company is given information on 100 randomly selected DMVs across the country.
    For each DMV the annual driving test pass rate is recorded, along with other characteristics describing the DMV.
    Can logistic regression with multiple predictors be used to predict annual driving test pass rate for DMVs in this setting?
    Explain your reasoning.

\vfill

2.  **Oceans and skin cancer.** A researcher wants to investigate the relationship between living within 10 miles of an ocean for at least one year of life and developing skin cancer before the age of 50.

    a.  Explain why logistic regression can be used to study the relationship between these two binary variables?
        What is the technical assumption describing the relationship between the response (outcome) and explanatory (predictor) variables?

    b.  What other methods covered in this text might be used to address the research question of interest? What advantages does logistic regression have over these methods?

\vfill

3.  **Marijuana use in college.** Researchers studying whether the value systems of adolescents conflict with those of their parents asked 445 college students if they use marijuana.
    They also asked the students' parents if they used marijuana when they were in college.
    Based on the regression output shown below for predicting student drug use from parent drug use, evaluate whether parents' marijuana usage is a discernible predictor of their kids' marijuana usage. 
    State the hypotheses, the test statistics, the p-value, and the conclusion in context of the data and the research question.[^_26-ex-inf-model-logistic-1]
    [@Ellis:1979]

    ```{r}
    glm(student ~ parents, data = drug_use, family = "binomial") |>
      tidy() |>
      mutate(p.value = ifelse(p.value < 0.0001, "<0.0001", round(p.value, 4))) |>
      kbl(linesep = "", booktabs = TRUE, align = "lrrrr", digits = 3) |>
      kable_styling(
        bootstrap_options = c("striped", "condensed"), 
        latex_options = "HOLD_position",
        full_width = FALSE
      ) |>
      column_spec(1, width = "10em", monospace = TRUE) |>
      column_spec(2:5, width = "5em")
    ```

\vfill

4.  **Treating heart attacks.** Researchers studying the effectiveness of Sulfinpyrazone in the prevention of sudden death after a heart attack conducted a randomized experiment on 1,475 patients.
    Based on the regression output shown below for predicting the outcome (`died` or `lived`, where success is defined as `lived`) from the treatment group (`control` and `treatment`), evaluate whether treatment group is a discernible predictor of the outcome. 
    State the hypotheses, the test statistics, the p-value, and the conclusion in context of the data and the research question.[^_26-ex-inf-model-logistic-2]
    [@Anturane:1980]

    ```{r}
    glm(outcome ~ group, data = sulphinpyrazone, family = "binomial") |>
     tidy() |>
     mutate(p.value = ifelse(p.value < 0.0001, "<0.0001", round(p.value, 4))) |>
     kbl(linesep = "", booktabs = TRUE, align = "lrrrr", digits = 3) |>
     kable_styling(
       bootstrap_options = c("striped", "condensed"), 
       latex_options = "HOLD_position",
       full_width = FALSE
      ) |>
     column_spec(1, width = "10em", monospace = TRUE) |>
     column_spec(2:5, width = "5em")
    ```

\clearpage

5.  **Possum classification, cross-validation.** The common brushtail possum of the Australia region is a bit cuter than its distant cousin, the American opossum.
    We consider 104 brushtail possums from two regions in Australia, where the possums may be considered a random sample from the population.
    The first region is Victoria, which is in the eastern half of Australia and traverses the southern coast.
    The second region consists of New South Wales and Queensland, which make up eastern and northeastern Australia.
    We use logistic regression to differentiate between possums in these two regions.
    The outcome variable, called `pop`, takes value 1 when a possum is from Victoria and 0 when it is from New South Wales or Queensland.[^_26-ex-inf-model-logistic-3]
    
    ```{r}
    possum <- openintro::possum |>
      mutate(pop = as.factor(ifelse(pop == "Vic", "Victoria", "other")))

    set.seed(4)
    possum_CV1 <- train(pop ~ tail_l,
      data = possum,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 4,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    possum_CV2 <- train(pop ~ total_l + sex,
      data = possum,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 4,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    ```
    
    :::: {layout="[0.49, -0.02, 0.49]" layout-valign="top"}
    
    :::{#smaller}
    $$
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 + \beta_1 \times \texttt{tail\_l}
    $$
    
    ```{r}
    #| out-width: 100%
    #| fig-width: 5
    #| fig-asp: 1
    possum_CV1$pred |>
      select(obs, pred, Resample) |>
      table() |>
      as.data.frame() |>
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      labs(
        x = "Predicted region",
        y = "Observed region",
        title = "Model with tail length as predictor"
      ) +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6])
    ```
    :::

    :::{#larger}
    $$
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 + \beta_1 \times \texttt{total\_l} + \beta_2\times \texttt{sex}
    $$

    ```{r}
    #| out-width: 100%
    #| fig-width: 5
    #| fig-asp: 1
    possum_CV2$pred |>
      select(obs, pred, Resample) |>
      table() |>
      as.data.frame() |>
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      labs(
        x = "Predicted region",
        y = "Observed region",
        title = "Model with total length and sex as predictors"
      ) +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6])
    ```
    :::
    
    ::::

    a.  How many observations are in Fold2?
        Use the model with only tail length as a predictor variable.
        Of the observations in Fold2, how many of them were correctly predicted to be from Vicotria?
        How many of them were incorrectly predicted to be from Victoria?

    b.  How many observations are used to build the model which predicts for the observations in Fold2?

    c.  For one of the cross-validation folds, how many coefficients were estimated for the model which uses tail length as a predictor?
        For one of the cross-validation folds, how many coefficients were estimated for the model which uses total length and sex as predictors?

\clearpage

6.  **Premature babies, cross-validation.** US Department of Health and Human Services, Centers for Disease Control and Prevention collect information on births recorded in the country.
    The data used here are a random sample of 1000 births from 2014 (with some rows removed due to missing data).
    We use logistic regression to model whether the baby is premature from various explanatory variables.[^_26-ex-inf-model-logistic-4]
    [@data:births14]
    
    ```{r}
    births14_nona <- births14 |>
      select(-fage) |>
      drop_na() |>
      mutate(lowbw = as.factor(ifelse(lowbirthweight == "low", "low", "not_low"))) |>
      mutate(premie = as.factor(ifelse(premie == "premie", "premie", "full_term")))

    set.seed(473)
    premie_CV1 <- train(premie ~ mage + weight + mature + visits + gained + habit,
      data = births14_nona,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 3,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    set.seed(473)
    premie_CV2 <- train(premie ~ weight + mature,
      data = births14_nona,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 3,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    ```
    
    :::: {layout="[0.49, -0.02, 0.49]" layout-valign="bottom"}

    :::{#larger}
    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 &+ \beta_1\times \texttt{mage} \\
    &+ \beta_2 \times \texttt{weight} \\
    &+ \beta_3 \times \texttt{mature} \\
    &+ \beta_4 \times \texttt{visits} \\
    &+ \beta_5 \times \texttt{gained} \\
    &+ \beta_6 \times \texttt{habit}
    \end{aligned}
    $$
    
    ```{r}
    #| out-width: 100%
    #| fig-width: 5
    #| fig-asp: 0.5
    premie_CV1$pred |>
      select(obs, pred, Resample) |>
      table() |>
      as.data.frame() |>
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      labs(
        x = "Predicted birth",
        y = "Observed birth",
        title = "Model with 6 predictors"
      ) +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6])
    ```
    :::
    
    :::{#smaller}
    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg)  = \beta_0 &+ \beta_1\times \texttt{weight} \\
    &+ \beta_2 \times \texttt{mature}
    \end{aligned}
    $$
    
    ```{r}
    #| out-width: 100%
    #| fig-width: 5
    #| fig-asp: 0.5
    premie_CV2$pred |>
      select(obs, pred, Resample) |>
      table() |>
      as.data.frame() |>
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      labs(
        x = "Predicted birth",
        y = "Observed birth",
        title = "Model with 2 predictors"
      ) +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6])
    ```
    :::
    ::::

    a.  How many observations are in Fold2?
        Use the model with only `weight` and `mature` as predictor variables.
        Of the observations in Fold2, how many of them were correctly predicted to be premature?
        How many of them were incorrectly predicted to be premature?

    b.  How many observations are used to build the model which predicts for the observations in Fold2?

    c.  In the original dataset, are most of the births premature or full term?
        Explain.

    d.  For one of the cross-validation folds, how many coefficients were estimated for the model which uses `mage`, `weight`, `mature`, `visits`, `gained`, and `habit` as predictors?
        For one of the cross-validation folds, how many coefficients were estimated for the model which uses `weight` and `mature` as predictors?

\clearpage

7.  **Possum classification, cross-validation to choose model.** In this exercise we consider 104 brushtail possums from two regions in Australia (the first region is Victoria and the second is New South Wales and Queensland), where the possums may be considered a random sample from the population.
    We use logistic regression to classify the possums into the two regions.
    The outcome variable, called `pop`, takes value 1 when a possum is from Victoria and 0 when it is from New South Wales or Queensland.
    
    ```{r}
    possum <- openintro::possum |>
      mutate(pop = as.factor(ifelse(pop == "Vic", "Victoria", "other")))

    set.seed(4)
    possum_CV1 <- train(pop ~ tail_l,
      data = possum,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 4,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    possum_CV2 <- train(pop ~ total_l + sex,
      data = possum,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 4,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    ```

    :::: {layout="[0.49, -0.02, 0.49]" layout-valign="top"}
    
    :::{#smaller}
    $$
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 + \beta_1\times \texttt{tail\_l}
    $$
    
    ```{r}
    #| out-width: 100%
    #| fig-width: 5
    #| fig-asp: 1
    possum_CV1$pred |>
      select(obs, pred, Resample) |>
      table() |>
      as.data.frame() |>
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      labs(
        x = "Predicted region",
        y = "Observed region",
        title = "Model with tail length as predictor"
      ) +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6])
    ```
    :::

    :::{#larger}
    $$
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 + \beta_1 \times \texttt{total\_l} + \beta_2 \times \texttt{sex}
    $$

    ```{r}
    #| out-width: 100%
    #| fig-width: 5
    #| fig-asp: 1
    possum_CV2$pred |>
      select(obs, pred, Resample) |>
      table() |>
      as.data.frame() |>
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      labs(
        x = "Predicted region",
        y = "Observed region",
        title = "Model with total length and sex as predictors"
      ) +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6])
    ```
    :::
    
    ::::

    a.  For the model with tail length, how many of the observations were correctly classified?
        What proportion of the observations were correctly classified?

    b.  For the model with total length and sex, how many of the observations were correctly classified?
        What proportion of the observations were correctly classified?

    c.  If you have to choose between using only tail length as a predictor versus using total length and sex as predictors (for classification into region), which model would you choose?
        Explain.

    d.  Given the predictions above, what third model might be preferable to either of the models above?
        Explain.

\clearpage

8.  **Premature babies, cross-validation to choose model.** US Department of Health and Human Services, Centers for Disease Control and Prevention collect information on births recorded in the country.
    The data used here are a random sample of 1000 births from 2014 (with some rows removed due to missing data).
    We use logistic regression to model whether the baby is premature from various explanatory variables.
    [@data:births14]
    
    ```{r}
    births14_nona <- births14 |>
      select(-fage) |>
      drop_na() |>
      mutate(lowbw = as.factor(ifelse(lowbirthweight == "low", "low", "not_low"))) |>
      mutate(premie = as.factor(ifelse(premie == "premie", "premie", "full_term")))

    set.seed(473)
    premie_CV1 <- train(premie ~ mage + weight + mature + visits + gained + habit,
      data = births14_nona,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 3,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    set.seed(473)
    premie_CV2 <- train(premie ~ weight + mature,
      data = births14_nona,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 3,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    ```

    :::: {layout="[0.49, -0.02, 0.49]" layout-valign="bottom"}

    :::{#larger}
    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 &+ \beta_1 \times \texttt{mage} \\
    &+ \beta_2 \times \texttt{weight} \\
    &+ \beta_3 \times \texttt{mature} \\
    &+ \beta_4 \times \texttt{visits} \\
    &+ \beta_5 \times \texttt{gained} \\
    &+ \beta_6 \times \texttt{habit}
    \end{aligned}
    $$
    
    ```{r}
    #| out-width: 100%
    #| fig-width: 5
    #| fig-asp: 0.5
    premie_CV1$pred |>
      select(obs, pred, Resample) |>
      table() |>
      as.data.frame() |>
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      labs(
        x = "Predicted birth",
        y = "Observed birth",
        title = "Model with 6 predictors"
      ) +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6])
    ```
    :::
    
    :::{#smaller}
    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 &+ \beta_1\times \texttt{weight} \\
    &+ \beta_2 \times \texttt{mature}
    \end{aligned}
    $$
    
    ```{r}
    #| out-width: 100%
    #| fig-width: 5
    #| fig-asp: 0.5
    premie_CV2$pred |>
      select(obs, pred, Resample) |>
      table() |>
      as.data.frame() |>
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      labs(
        x = "Predicted birth",
        y = "Observed birth",
        title = "Model with 2 predictors"
      ) +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6])
    ```
    :::
    ::::

    a.  For the model with 6 predictors, how many of the observations were correctly classified?
        What proportion of the observations were correctly classified?

    b.  For the model with 2 predictors, how many of the observations were correctly classified?
        What proportion of the observations were correctly classified?

    c.  If you have to choose between the model with 6 predictors and the model with 2 predictors (for predicting whether a baby will be premature), which model would you choose?
        Explain.

[^_26-ex-inf-model-logistic-1]: The [`drug_use`](http://openintrostat.github.io/openintro/reference/drug_use.html) data used in this exercise can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.

[^_26-ex-inf-model-logistic-2]: The [`sulphinpyrazone`](http://openintrostat.github.io/openintro/reference/sulphinpyrazone.html) data used in this exercise can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.

[^_26-ex-inf-model-logistic-3]: The [`possum`](http://openintrostat.github.io/openintro/reference/possum.html) data used in this exercise can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.

[^_26-ex-inf-model-logistic-4]: The [`births14`](http://openintrostat.github.io/openintro/reference/births14.html) data used in this exercise can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.
