1.  **Passing the driver's test.** A consulting company is hired to assess whether certain characteristics of a DMV (e.g., location, number of test takers, number of test givers, hours of operation, etc.) is associated with the pass rate of the driver's test.
    The company is given detailed information about 100 randomly selected DMVs across the country.
    For each DMV the annual driving test pass rate is recorded, along with other variables describing the DMV.
    Is multiple logistic regression the correct model to use in this setting?
    Explain why or why not.

2.  **Oceans and skin cancer.** A researcher hopes to investigate the relationship between living within 10 miles of an ocean (for at least one year of life) and developing skin cancer before the age of 50.
    Before starting the study, the researcher wants to know if logistic regression is the right method to use for their analysis.

    a.  Can the researcher use logistic regression to study two binary variables?
        What is the technical assumption describing the relationship between the response (outcome) and explanatory (predictor) variables?

    b.  Is logistic regression the only method that could be used to study the relationship?
        What other methods covered in this text might be used to address the research question of interest?

    c.  What advantages does logistic regression have over the previously covered methods you desribed in (b)?

3.  **Marijuana use in college.** Researchers studying whether the value systems of adolescents conflict with those of their parents asked 445 college students if they use marijuana.
    They also asked the students' parents if they used marijuana when they were in college.
    The following model was fit to predict student drug use from parent drug use.[^_26-ex-inf-model-logistic-1]
    [@Ellis:1979]

    ```{r}
    drug_use %>%
      glm(student ~ parents, data = ., family = "binomial") %>%
      tidy() %>%
      mutate(p.value = ifelse(p.value < 0.0001, "<0.0001", round(p.value, 4))) %>%
      kbl(linesep = "", booktabs = TRUE, align = "lrrrr", digits = 3) %>%
      kable_styling(bootstrap_options = c("striped", "condensed"), 
                    latex_options = "HOLD_position",
                    full_width = FALSE) %>%
      column_spec(1, width = "10em", monospace = TRUE) %>%
      column_spec(2:5, width = "5em")
    ```

    a.  State the hypotheses for evaluating whether parents' marijuana usage is a discernible predictor of their kids' marijuana usage.

    b.  Based on the regression output, state the sample statistic and the p-value of the test.

    c.  State the conclusion of the hypothesis test in context of the data and the research question.

4.  **Treating heart attacks.** Researchers studying the effectiveness of Sulfinpyrazone in the prevention of sudden death after a heart attack conducted a randomized experiment on 1,475 patients.
    The following model was fit to predict the outcome (`died` or `lived`, where success is defined as `lived`) from the treatment group (`control` and `treatment`).[^_26-ex-inf-model-logistic-2]
    [@Anturane:1980]

    ```{r}
       sulphinpyrazone %>%
     glm(outcome ~ group, data = ., family = "binomial") %>%
     tidy() %>%
     mutate(p.value = ifelse(p.value < 0.0001, "<0.0001", round(p.value, 4))) %>%
     kbl(linesep = "", booktabs = TRUE, align = "lrrrr", digits = 3) %>%
     kable_styling(bootstrap_options = c("striped", "condensed"), 
                   latex_options = "HOLD_position",
                   full_width = FALSE) %>%
     column_spec(1, width = "10em", monospace = TRUE) %>%
     column_spec(2:5, width = "5em")
    ```

    a.  State the hypotheses for evaluating whether treatment group is a discernible predictor of the outcome.

    b.  Based on the regression output, state the sample statistic and the p-value of the test.

    c.  State the conclusion of the hypothesis test in context of the data and the research question.

5.  **Possum classification, cross-validation.** The common brushtail possum of the Australia region is a bit cuter than its distant cousin, the American opossum.
    We consider 104 brushtail possums from two regions in Australia, where the possums may be considered a random sample from the population.
    The first region is Victoria, which is in the eastern half of Australia and traverses the southern coast.
    The second region consists of New South Wales and Queensland, which make up eastern and northeastern Australia.
    We use logistic regression to differentiate between possums in these two regions.
    The outcome variable, called `pop`, takes value 1 when a possum is from Victoria and 0 when it is from New South Wales or Queensland.[^_26-ex-inf-model-logistic-3]

    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 &+ \beta_1\times \texttt{tail\_l}
    \end{aligned}
    $$

    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 &+ \beta_1\times \texttt{total\_l} + \beta_2\times     \texttt{sex}
    \end{aligned}
    $$

    ```{r}
    possum <- openintro::possum %>%
      mutate(pop = as.factor(ifelse(pop == "Vic", "Victoria", "other")))

    set.seed(4)
    possum_CV1 <- train(pop ~ tail_l,
      data = possum,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 4,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    possum_CV2 <- train(pop ~ total_l + sex,
      data = possum,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 4,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )

    possum_CV1$pred %>%
      select(obs, pred, Resample) %>%
      table() %>%
      as.data.frame() %>%
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      ylab("Observed region") +
      xlab("Predicted region") +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6]) +
      ggtitle("Model with tail length predictor")

    possum_CV2$pred %>%
      select(obs, pred, Resample) %>%
      table() %>%
      as.data.frame() %>%
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      ylab("Observed region") +
      xlab("Predicted region") +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6]) +
      ggtitle("Model with total length and sex as predictors")
    ```

    a.  How many observations are in Fold2?
        Use the model with only tail length as a predictor variable.
        Of the observations in Fold2, how many of them were correctly predicted to be from Vicotria?
        How many of them were incorrectly predicted to be from Victoria?

    b.  How many observations are used to build the model which predicts for the observations in Fold2?

    c.  For one of the cross-validation folds, how many coefficients were estimated for the model which uses tail length as a predictor?
        For one of the cross-validation folds, how many coefficients were estimated for the model which uses total length and sex as predictors?

6.  **Premature babies, cross-validation.** US Department of Health and Human Services, Centers for Disease Control and Prevention collect information on births recorded in the country.
    The data used here are a random sample of 1000 births from 2014 (with some rows removed due to missing data).
    Here, we use logistic regression to model whether or not the baby is premature from various explanatory variables.[^_26-ex-inf-model-logistic-4]
    [@data:births14]

    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg)  = \beta_0 &+ \beta_1\times \texttt{mage} + \beta_2\times     \texttt{weight}\\
    &+ \beta_3 \times \texttt{mature} + \beta_4 \times \texttt{visits}\\
    &+ \beta_5 \times \texttt{gained}+ \beta_6 \times \texttt{habit}\\
    \end{aligned}
    $$

    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg)  = \beta_0 &+ \beta_1\times \texttt{weight} + \beta_2\times     \texttt{mature}
    \end{aligned}
    $$

    ```{r}
    #| fig-asp: 0.5
    births14_nona <- births14 %>%
      select(-fage) %>%
      drop_na() %>%
      mutate(lowbw = as.factor(ifelse(lowbirthweight == "low", "low", "not_low"))) %>%
      mutate(premie = as.factor(ifelse(premie == "premie", "premie", "full_term")))

    set.seed(473)
    premie_CV1 <- train(premie ~ mage + weight + mature + visits + gained + habit,
      data = births14_nona,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 3,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    set.seed(473)
    premie_CV2 <- train(premie ~ weight + mature,
      data = births14_nona,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 3,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )

    premie_CV1$pred %>%
      select(obs, pred, Resample) %>%
      table() %>%
      as.data.frame() %>%
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      ylab("Observed birth") +
      xlab("Predicted birth") +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6]) +
      ggtitle("Model with 6 predictors")

    premie_CV2$pred %>%
      select(obs, pred, Resample) %>%
      table() %>%
      as.data.frame() %>%
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      ylab("Observed birth") +
      xlab("Predicted birth") +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6]) +
      ggtitle("Model with 2 predictors")
    ```

    a.  How many observations are in Fold2?
        Use the model with only `weight` and `mature` as predictor variables.
        Of the observations in Fold2, how many of them were correctly predicted to be premature?
        How many of them were incorrectly predicted to be premature?

    b.  How many observations are used to build the model which predicts for the observations in Fold2?

    c.  In the original dataset, are most of the births premature or full term?
        Explain.

    d.  For one of the cross-validation folds, how many coefficients were estimated for the model which uses `mage`, `weight`, `mature`, `visits`, `gained`, and `habit` as predictors?
        For one of the cross-validation folds, how many coefficients were estimated for the model which uses `weight` and `mature` as predictors?

7.  **Possum classification, cross-validation to choose model.** In this exercise we consider 104 brushtail possums from two regions in Australia (the first region is Victoria and the second is New South Wales and Queensland), where the possums may be considered a random sample from the population.
    We use logistic regression to classify the possums into the two regions.
    The outcome variable, called `pop`, takes value 1 when a possum is from Victoria and 0 when it is from New South Wales or Queensland.

    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 &+ \beta_1\times \texttt{tail\_l}
    \end{aligned}
    $$

    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg) = \beta_0 &+ \beta_1\times \texttt{total\_l} + \beta_2\times     \texttt{sex}
    \end{aligned}
    $$

    ```{r}
    possum <- openintro::possum %>%
      mutate(pop = as.factor(ifelse(pop == "Vic", "Victoria", "other")))

    set.seed(4)
    possum_CV1 <- train(pop ~ tail_l,
      data = possum,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 4,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    possum_CV2 <- train(pop ~ total_l + sex,
      data = possum,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 4,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )

    possum_CV1$pred %>%
      select(obs, pred, Resample) %>%
      table() %>%
      as.data.frame() %>%
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      ylab("Observed region") +
      xlab("Predicted region") +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6]) +
      ggtitle("Model with tail length predictor")

    possum_CV2$pred %>%
      select(obs, pred, Resample) %>%
      table() %>%
      as.data.frame() %>%
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      ylab("Observed region") +
      xlab("Predicted region") +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6]) +
      ggtitle("Model with total length and sex as predictors")
    ```

    a.  For the model with tail length, how many of the observations were correctly classified?
        What proportion of the observations were correctly classified?

    b.  For the model with total length and sex, how many of the observations were correctly classified?
        What proportion of the observations were correctly classified?

    c.  If you have to choose between using only tail length as a predictor versus using total length and sex as predictors (for classification into region), which model would you choose?
        Explain.

    d.  Given the predictions above, what third model might be preferable to either of the models above?
        Explain.

8.  **Premature babies, cross-validation to choose model.** US Department of Health and Human Services, Centers for Disease Control and Prevention collect information on births recorded in the country.
    The data used here are a random sample of 1000 births from 2014 (with some rows removed due to missing data).
    Here, we use logistic regression to model whether or not the baby is premature from various explanatory variables.
    [@data:births14]

    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg)  = \beta_0 &+ \beta_1\times \texttt{mage} + \beta_2\times     \texttt{weight}\\
    &+ \beta_3 \times \texttt{mature} + \beta_4 \times \texttt{visits}\\
    &+ \beta_5 \times \texttt{gained}+ \beta_6 \times \texttt{habit}\\
    \end{aligned}
    $$

    $$
    \begin{aligned}
    \log_e \bigg(\frac{p}{1-p}\bigg)  = \beta_0 &+ \beta_1\times \texttt{weight} + \beta_2\times     \texttt{mature}
    \end{aligned}
    $$

    ```{r}
    #| fig-asp: 0.5
    births14_nona <- births14 %>%
      select(-fage) %>%
      drop_na() %>%
      mutate(lowbw = as.factor(ifelse(lowbirthweight == "low", "low", "not_low"))) %>%
      mutate(premie = as.factor(ifelse(premie == "premie", "premie", "full_term")))

    set.seed(473)
    premie_CV1 <- train(premie ~ mage + weight + mature + visits + gained + habit,
      data = births14_nona,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 3,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )
    set.seed(473)
    premie_CV2 <- train(premie ~ weight + mature,
      data = births14_nona,
      na.action = na.omit,
      method = "glm",
      family = "binomial",
      trControl = trainControl(
        method = "cv", number = 3,
        classProbs = TRUE,
        savePredictions = TRUE
      )
    )

    premie_CV1$pred %>%
      select(obs, pred, Resample) %>%
      table() %>%
      as.data.frame() %>%
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      ylab("Observed birth") +
      xlab("Predicted birth") +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6]) +
      ggtitle("Model with 6 predictors")

    premie_CV2$pred %>%
      select(obs, pred, Resample) %>%
      table() %>%
      as.data.frame() %>%
      ggplot(aes(x = forcats::fct_rev(pred), y = obs)) +
      geom_tile(aes(fill = Freq)) +
      ylab("Observed birth") +
      xlab("Predicted birth") +
      geom_text(aes(label = sprintf("%1.0f", Freq)), vjust = 1) +
      facet_wrap(~Resample) +
      theme(legend.position = "none") +
      scale_fill_continuous(high = IMSCOL["blue", 1], low = IMSCOL["blue", 6]) +
      ggtitle("Model with 2 predictors")
    ```

    a.  For the model with 6 predictors, how many of the observations were correctly classified?
        What proportion of the observations were correctly classified?

    b.  For the model with 2 predictors, how many of the observations were correctly classified?
        What proportion of the observations were correctly classified?

    c.  If you have to choose between the model with 6 predictors and the model with 2 predictors (for predicting whether a baby will be premature), which model would you choose?
        Explain.

[^_26-ex-inf-model-logistic-1]: The [`drug_use`](http://openintrostat.github.io/openintro/reference/drug_use.html) data used in this exercise can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.

[^_26-ex-inf-model-logistic-2]: The [`sulphinpyrazone`](http://openintrostat.github.io/openintro/reference/sulphinpyrazone.html) data used in this exercise can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.

[^_26-ex-inf-model-logistic-3]: The [`possum`](http://openintrostat.github.io/openintro/reference/possum.html) data used in this exercise can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.

[^_26-ex-inf-model-logistic-4]: The [`births14`](http://openintrostat.github.io/openintro/reference/births14.html) data used in this exercise can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.
