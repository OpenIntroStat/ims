1. Paired, data are recorded in the same cities at two different time points. The temperature in a city at one point is not independent of the temperature in the same city at another time point

1. \(a) Since it's the same students at the beginning and the end of the semester, there is a pairing between the datasets, for a given student their beginning and end of semester grades are dependent. (b) Since the subjects were sampled randomly, each observation in the men's group does not have a special correspondence with exactly one observation in the other (women's) group. (c) Since it's the same subjects at the beginning and the end of the study, there is a pairing between the datasets, for a subject student their beginning and end of semester artery thickness are dependent. (d) Since it's the same subjects at the beginning and the end of the study, there is a pairing between the datasets, for a subject student their beginning and end of semester weights are dependent.

1. False. While it is true that paired analysis requires equal sample sizes, only having the equal sample sizes isn't, on its own, sufficient for doing a paired test. Paired tests require that there be a special correspondence between each pair of observations in the two groups.

1. The data are paired, since this is a before-after measurement of the same trees, so we will construct a confidence interval using the differences summary statistics. But before we proceed with a confidence interval, we must first check conditions: Independent: this is satisfied since the trees were randomly sampled. Normality: since $n = 50 \geq 30$, we only need consider whether there are any particularly extreme outliers. None are mentioned, and it doesn't seem like we'd expect to observe any such cases from data of this type, so we'll consider this condition to be satisfied. With the conditions satisfied, we can proceed with calculations. First, compute the standard error and degrees of freedom: $SE = \frac{7.2}{\sqrt{50}} = 1.02$ and $df = 50 - 1 = 49$. Next, we find $t^{\star} = 2.68$ for a 99% confidence interval using a $t$-distribution with 49 degrees of freedom, and then we construct the confidence interval: $\bar{x} \pm t^{\star} \times SE =  12.5 \pm 2.68 \times 1.02 = (9.77, 15.23)$. We are 99% confident that the average growth of young trees in this area during the 10-year period was 9.77 to 15.23 feet.

1. \(a) No. (b) Yes. (c) No. (d) No and yes. (e) Yes.

1. \(a) Let $diff = 2018 - 1948$. Then, $H_0: \mu_{diff} = 0$ and $H_A: \mu_{diff} \ne 0$. (b) The observed average of difference is just outside the randomized differences. (c) Since the p-value $<$ 0.05, reject $H_0$. The data provide convincing evidence of a difference between the average number of 90F degree days in 2018 and the average number of 90F degree days in 1948.

1. \(a) For each observation in one dataset, there is exactly one specially corresponding observation in the other dataset for the same geographic location. The data are paired. (b) $H_0: \mu_{\text{diff}} = 0$ (There is no difference in average number of days exceeding 90F in 1948 and 2018 for NOAA stations.) $H_A: \mu_{\text{diff}} \neq 0$ (There is a difference.) (c) Locations were randomly sampled, so independence is reasonable. The sample size is at least 30, so we're just looking for particularly extreme outliers: none are present (the observation off left in the histogram would be considered a clear outlier, but not a particularly extreme one). Therefore, the conditions are satisfied. (d) $SE = 17.2 / \sqrt{197} = 1.23$. $T = \frac{2.9 - 0}{1.23} = 2.36$ with degrees of freedom $df = 197 - 1 = 196$. This leads to a one-tail area of 0.0096 and a p-value of about 0.019. (e) Since the p-value is less than 0.05, we reject $H_0$. The data provide strong evidence that NOAA stations observed more 90F days in 2018 than in 1948. (f) Type 1 Error, since we may have incorrectly rejected $H_0$. This error would mean that NOAA stations did not actually observe a decrease, but the sample we took just so happened to make it appear that this was the case. (g) No, since we rejected $H_0$, which had a null value of 0.

1. \(a) $SE = 1.23$ and $z^{\star} = 1.65$. $2.9 \pm 1.65 \times 1.23 \to (0.87, 4.93)$. (b) We are 90% confident that there was an increase of 0.87 to 4.93 in the average number of days that hit 90F in 2018 relative to 1948 for NOAA stations. (c) Yes, since the interval lies entirely above 0.

1. \(a)These data are paired. For example, the Friday the 13th in say, September 1991, would probably be more similar to the Friday the 6th in September 1991 than to Friday the 6th in another month or year. (b) Let $\mu_{\textit{diff}} = \mu_{sixth} - \mu_{thirteenth}$. $H_0: \mu_{\textit{diff}} = 0$. $H_A: \mu_{\textit{diff}} \ne 0$. (c) Independence: The months selected are not random. However, if we think these dates are roughly equivalent to a simple random sample of all such Friday 6th/13th date pairs, then independence is reasonable. To proceed, we must make this strong assumption, though we should note this assumption in any reported results. Normality: With fewer than 10 observations, we would need to see clear outliers to be concerned. There is a borderline outlier on the right of the histogram of the differences, so we would want to report this in formal analysis results. (d) $T = 4.93$ for $df = 10 - 1 = 9$ $\to$ p-value = 0.001. (e) Since p-value $<$ 0.05, reject $H_0$. The data provide strong evidence that the average number of cars at the intersection is higher on Friday the 6$^{\text{th}}$ than on Friday the 13$^{\text{th}}$. (We should exercise caution about generalizing the interpetation to all intersections or roads.) (f) If the average number of cars passing the intersection actually was the same on Friday the 6$^{\text{th}}$ and $13^{th}$, then the probability that we would observe a test statistic so far from zero is less than 0.01.\ (g) We might have made a Type 1 Error, i.e., incorrectly rejected the null hypothesis.
