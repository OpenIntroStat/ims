{
  "hash": "bc6906a4788fb4ea7d335465f99bc5f1",
  "result": {
    "engine": "knitr",
    "markdown": "# Inference for comparing many means {#sec-inference-many-means}\n\n\n\n\n\n::: {.chapterintro data-latex=\"\"}\nIn [Chapter -@sec-inference-two-means] analysis was done to compare the average population value across two different groups.\nAn important aspect of the analysis was to look at the difference in sample means as an estimate for the difference in population means.\nWhen comparing more than two groups, the difference (i.e., subtraction) will not fully capture the nuance in variation across the three or more groups.\nAs with two groups, the research question will focus on whether the group membership is independent of the numerical response variable.\nHere, independence across groups means that knowledge of the observations in one group does not change what we would expect to happen in the other group.\nBut what happens if the groups are **dependent**?\nIn this section we focus on a new statistic which incorporates differences in means across more than two groups.\nAlthough the ideas in this chapter are quite similar to the t-test, they have earned themselves their own name: **AN**alysis **O**f **VA**riance, or ANOVA.\n:::\n\n\\index{analysis of variance (ANOVA)}\n\nSometimes we want to compare means across many groups.\nWe might initially think to do pairwise comparisons.\nFor example, if there were three groups, we might be tempted to compare the first mean with the second, then with the third, and then finally compare the second and third means for a total of three comparisons.\nHowever, this strategy can be treacherous.\nIf we have many groups and do many comparisons, it is likely that we will eventually find a difference just by chance, even if there is no difference in the populations.\nInstead, we should apply a holistic test to check whether there is evidence that at least one pair groups are in fact different, and this is where **ANOVA** saves the day.\n\n\n\n\n\nIn this section, we will learn a new method called **analysis of variance (ANOVA)** and a new test statistic called an $F$-statistic (which we will introduce in our discussion of mathematical models).\nANOVA uses a single hypothesis test to check whether the means across many groups are equal:\n\n-   $H_0:$ The mean outcome is the same across all groups. In statistical notation, $\\mu_1 = \\mu_2 = \\cdots = \\mu_k$ where $\\mu_i$ represents the mean of the outcome for observations in category $i.$\\\n-   $H_A:$ At least one mean is different.\n\nGenerally we must check three conditions on the data before performing ANOVA:\n\n-   the observations are independent within and between groups,\n-   the responses within each group are nearly normal, and\n-   the variability across the groups is about equal.\n\nWhen these three conditions are met, we may perform an ANOVA to determine whether the data provide convincing evidence against the null hypothesis that all the $\\mu_i$ are equal.\n\n::: {.workedexample data-latex=\"\"}\nCollege departments commonly run multiple sections of the same introductory course each semester because of high demand.\nConsider a statistics department that runs three sections of an introductory statistics course.\nWe might like to determine whether there are substantial differences in first exam scores in these three classes (Section A, Section B, and Section C).\nDescribe appropriate hypotheses to determine whether there are any differences between the three classes.\n\n------------------------------------------------------------------------\n\nThe hypotheses may be written in the following form:\n\n-   $H_0:$ The average score is identical in all sections, $\\mu_A = \\mu_B = \\mu_C$. Assuming each class is equally difficult, the observed difference in the exam scores is due to chance.\n-   $H_A:$ The average score varies by class. We would reject the null hypothesis in favor of the alternative hypothesis if there were larger differences among the class averages than what we might expect from chance alone.\n:::\n\nStrong evidence favoring the alternative hypothesis in ANOVA is described by unusually large differences among the group means.\nWe will soon learn that assessing the variability of the group means relative to the variability among individual observations within each group is key to ANOVA's success.\n\n::: {.workedexample data-latex=\"\"}\nExamine Figure \\@ref(fig:toyANOVA).\nCompare groups I, II, and III.\nCan you visually determine if the differences in the group centers is unlikely to have occurred if there were no differences in the groups?\nNow compare groups IV, V, and VI.\nDo these differences appear to be unlikely to have occurred if there were no differences in the groups?\n\n------------------------------------------------------------------------\n\nAny real difference in the means of groups I, II, and III is difficult to discern, because the data within each group are very volatile relative to any differences in the average outcome.\nOn the other hand, it appears there are differences in the centers of groups IV, V, and VI.\nFor instance, group V appears to have a higher mean than that of the other two groups.\nInvestigating groups IV, V, and VI, we see the differences in the groups' centers are noticeable because those differences are large *relative to the variability in the individual observations within each group*.\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Side-by-side dot plot for the outcomes for six groups. Two sets of groups: first set is comprised of Groups I, II, and III, the second set is comprised of Groups IV, V, and VI.](22-inference-many-means_files/figure-html/toyANOVA-1.png){width=90%}\n:::\n:::\n\n\n## Case study: Batting\n\nWe would like to discern whether there are real differences between the batting performance of baseball players according to their position: outfielder (OF), infielder (IF), and catcher (C).\nWe will use a dataset called `mlb_players_18`, which includes batting records of 429 Major League Baseball (MLB) players from the 2018 season who had at least 100 at bats.\nSix of the 429 cases represented in `mlb_players_18` are shown in Table \\@ref(tab:mlbBat18DataFrame), and descriptions for each variable are provided in Table \\@ref(tab:mlbBat18Variables).\nThe measure we will use for the player batting performance (the outcome variable) is on-base percentage (`OBP`).\nThe on-base percentage roughly represents the fraction of the time a player successfully gets on base or hits a home run.\n\n::: {.data data-latex=\"\"}\nThe [`mlb_players_18`](http://openintrostat.github.io/openintro/reference/mlb_players_18.html) data can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.\n:::\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Six cases and some of the variables from the `mlb_players_18` data frame.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> name </th>\n   <th style=\"text-align:left;\"> team </th>\n   <th style=\"text-align:left;\"> position </th>\n   <th style=\"text-align:right;\"> AB </th>\n   <th style=\"text-align:right;\"> H </th>\n   <th style=\"text-align:right;\"> HR </th>\n   <th style=\"text-align:right;\"> RBI </th>\n   <th style=\"text-align:right;\"> AVG </th>\n   <th style=\"text-align:right;\"> OBP </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Abreu, J </td>\n   <td style=\"text-align:left;\"> CWS </td>\n   <td style=\"text-align:left;\"> IF </td>\n   <td style=\"text-align:right;\"> 499 </td>\n   <td style=\"text-align:right;\"> 132 </td>\n   <td style=\"text-align:right;\"> 22 </td>\n   <td style=\"text-align:right;\"> 78 </td>\n   <td style=\"text-align:right;\"> 0.265 </td>\n   <td style=\"text-align:right;\"> 0.325 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Acuna Jr., R </td>\n   <td style=\"text-align:left;\"> ATL </td>\n   <td style=\"text-align:left;\"> OF </td>\n   <td style=\"text-align:right;\"> 433 </td>\n   <td style=\"text-align:right;\"> 127 </td>\n   <td style=\"text-align:right;\"> 26 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n   <td style=\"text-align:right;\"> 0.293 </td>\n   <td style=\"text-align:right;\"> 0.366 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Adames, W </td>\n   <td style=\"text-align:left;\"> TB </td>\n   <td style=\"text-align:left;\"> IF </td>\n   <td style=\"text-align:right;\"> 288 </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:right;\"> 34 </td>\n   <td style=\"text-align:right;\"> 0.278 </td>\n   <td style=\"text-align:right;\"> 0.348 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Adams, M </td>\n   <td style=\"text-align:left;\"> STL </td>\n   <td style=\"text-align:left;\"> IF </td>\n   <td style=\"text-align:right;\"> 306 </td>\n   <td style=\"text-align:right;\"> 73 </td>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:right;\"> 57 </td>\n   <td style=\"text-align:right;\"> 0.239 </td>\n   <td style=\"text-align:right;\"> 0.309 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Adduci, J </td>\n   <td style=\"text-align:left;\"> DET </td>\n   <td style=\"text-align:left;\"> IF </td>\n   <td style=\"text-align:right;\"> 176 </td>\n   <td style=\"text-align:right;\"> 47 </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:right;\"> 0.267 </td>\n   <td style=\"text-align:right;\"> 0.290 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Adrianza, E </td>\n   <td style=\"text-align:left;\"> MIN </td>\n   <td style=\"text-align:left;\"> IF </td>\n   <td style=\"text-align:right;\"> 335 </td>\n   <td style=\"text-align:right;\"> 84 </td>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:right;\"> 39 </td>\n   <td style=\"text-align:right;\"> 0.251 </td>\n   <td style=\"text-align:right;\"> 0.301 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Variables and their descriptions for the `mlb_players_18` dataset.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:left;\"> Description </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> name </td>\n   <td style=\"text-align:left;width: 30em; \"> Player name </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> team </td>\n   <td style=\"text-align:left;width: 30em; \"> The abbreviated name of the player's team </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> position </td>\n   <td style=\"text-align:left;width: 30em; \"> The player's primary field position (OF, IF, C) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> AB </td>\n   <td style=\"text-align:left;width: 30em; \"> Number of opportunities at bat </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> H </td>\n   <td style=\"text-align:left;width: 30em; \"> Number of hits </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> HR </td>\n   <td style=\"text-align:left;width: 30em; \"> Number of home runs </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> RBI </td>\n   <td style=\"text-align:left;width: 30em; \"> Number of runs batted in </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> AVG </td>\n   <td style=\"text-align:left;width: 30em; \"> Batting average, which is equal to H/AB </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> OBP </td>\n   <td style=\"text-align:left;width: 30em; \"> On-base percentage, which is roughly equal to the fraction of times a player gets on base or hits a home run </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n::: {.guidedpractice data-latex=\"\"}\nThe null hypothesis under consideration is the following: $\\mu_{OF} = \\mu_{IF} = \\mu_{C} % = \\mu_{DH}.$ Write the null and corresponding alternative hypotheses in plain language.[^22-inference-many-means-1]\n:::\n\n[^22-inference-many-means-1]: $H_0:$ The average on-base percentage is equal across the four positions.\n    $H_A:$ The average on-base percentage varies across some (or all) groups.\n\n::: {.workedexample data-latex=\"\"}\nThe player positions have been divided into three groups: outfield (OF), infield (IF), and catcher (C).\nWhat would be an appropriate point estimate of the on-base percentage by outfielders, $\\mu_{OF}$?\n\n------------------------------------------------------------------------\n\nA good estimate of the on-base percentage by outfielders would be the sample average of `OBP` for just those players whose position is outfield: $\\bar{x}_{OF} = 0.320.$\n:::\n\n## Randomization test for comparing many means {#sec-randANOVA}\n\nTable \\@ref(tab:mlbHRPerABSummaryTable) provides summary statistics for each group.\nA side-by-side box plot for the on-base percentage is shown in Figure \\@ref(fig:mlbANOVABoxPlot).\nNotice that the variability appears to be approximately constant across groups; nearly constant variance across groups is an important assumption that must be satisfied before we consider the ANOVA approach.\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Summary statistics of on-base percentage, split by player position.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Position </th>\n   <th style=\"text-align:center;\"> n </th>\n   <th style=\"text-align:center;\"> Mean </th>\n   <th style=\"text-align:center;\"> SD </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;width: 6em; \"> OF </td>\n   <td style=\"text-align:center;width: 6em; \"> 160 </td>\n   <td style=\"text-align:center;width: 6em; \"> 0.320 </td>\n   <td style=\"text-align:center;width: 6em; \"> 0.043 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 6em; \"> IF </td>\n   <td style=\"text-align:center;width: 6em; \"> 205 </td>\n   <td style=\"text-align:center;width: 6em; \"> 0.318 </td>\n   <td style=\"text-align:center;width: 6em; \"> 0.038 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 6em; \"> C </td>\n   <td style=\"text-align:center;width: 6em; \"> 64 </td>\n   <td style=\"text-align:center;width: 6em; \"> 0.302 </td>\n   <td style=\"text-align:center;width: 6em; \"> 0.038 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Side-by-side box plot of the on-base percentage for 429 players across three groups. There is one prominent outlier visible in the infield group, but with 205 observations in the infield group, this outlier is not extreme enough to have an impact on the calculations, so it is not a concern for moving forward with the analysis.](22-inference-many-means_files/figure-html/mlbANOVABoxPlot-1.png){width=90%}\n:::\n:::\n\n\n::: {.workedexample data-latex=\"\"}\nThe largest difference between the sample means is between the catcher and the outfielder positions.\nConsider again the original hypotheses:\n\n-   $H_0:$ $\\mu_{OF} = \\mu_{IF} = \\mu_{C}$\n-   $H_A:$ The average on-base percentage $(\\mu_i)$ varies across some (or all) groups.\n\nWhy might it be inappropriate to run the test by simply estimating whether the difference of $\\mu_{C}$ and $\\mu_{OF}$ is \"statistically discernible\" at a 0.05 discernibility level?\n\n------------------------------------------------------------------------\n\nThe primary issue here is that we are inspecting the data before picking the groups that will be compared.\nIt is inappropriate to examine all data by eye (informal testing) and only afterwards decide which parts to formally test.\nThis is called **data snooping** or **data fishing**.\nNaturally, we would pick the groups with the large differences for the formal test, and this would leading to an inflation in the Type 1 Error rate.\nTo understand this better, let's consider a slightly different problem.\n\nSuppose we are to measure the aptitude for students in 20 classes in a large elementary school at the beginning of the year.\nIn this school, all students are randomly assigned to classrooms, so any differences we observe between the classes at the start of the year are completely due to chance.\nHowever, with so many groups, we will probably observe a few groups that look rather different from each other.\nIf we select only these classes that look so different and then perform a formal test, we will probably make the wrong conclusion that the assignment wasn't random.\nWhile we might only formally test differences for a few pairs of classes, we informally evaluated the other classes by eye before choosing the most extreme cases for a comparison.\n:::\n\nFor additional information on the ideas expressed above, we recommend reading about the **prosecutor's fallacy**.[^22-inference-many-means-2]\n\n[^22-inference-many-means-2]: See, for example, [this blog post](https://statmodeling.stat.columbia.edu/2007/05/18/the_prosecutors/).\n\n\n\n\n\n### Observed data\n\nIn the next section we will learn how to use the $F$ statistic to test whether observed differences in sample means could have happened just by chance even if there was no difference in the respective population means.\n\nThe method of analysis of variance in this context focuses on answering one question: is the variability in the sample means so large that it seems unlikely to be from chance alone?\nThis question is different from earlier testing procedures since we will *simultaneously* consider many groups, and evaluate whether their sample means differ more than we would expect from natural variation.\nWe call this variability the **mean square between groups (MSG)**, and it has an associated degrees of freedom, $df_{G} = k - 1$ when there are $k$ groups.\nThe $MSG$ can be thought of as a scaled variance formula for means.\nIf the null hypothesis is true, any variation in the sample means is due to chance and shouldn't be too large.\nDetails of $MSG$ calculations are provided in the footnote.[^22-inference-many-means-3]\nHowever, we typically use software for these computations.\n\\index{degrees of freedom}\n\n[^22-inference-many-means-3]: Let $\\bar{x}$ represent the mean of outcomes across all groups.\n    Then the mean square between groups is computed as $MSG = \\frac{1}{df_{G}}SSG = \\frac{1}{k-1}\\sum_{i=1}^{k} n_{i} \\left(\\bar{x}_{i} - \\bar{x}\\right)^2$ where $SSG$ is called the **sum of squares between groups** and $n_{i}$ is the sample size of group $i.$\n\n\n\n\n\nThe mean square between the groups is, on its own, quite useless in a hypothesis test.\nWe need a benchmark value for how much variability should be expected among the sample means if the null hypothesis is true.\nTo this end, we compute a pooled variance estimate, often abbreviated as the **mean square error (**$MSE)$, which has an associated degrees of freedom value $df_E = n - k.$ It is helpful to think of $MSE$ as a measure of the variability within the groups.\nDetails of the computations of the $MSE$ and a link to an extra online section for ANOVA calculations are provided in the footnote.[^22-inference-many-means-4]\n\n[^22-inference-many-means-4]: See [additional details on ANOVA calculations](https://www.openintro.org/download.php?file=stat_extra_anova_calculations) for interested readers.\n    Let $\\bar{x}$ represent the mean of outcomes across all groups.\n    Then the **sum of squares total (**$SST)$ is computed as $$SST = \\sum_{i=1}^{n} \\left(x_{i} - \\bar{x}\\right)^2$$ where the sum is over all observations in the dataset.\n    Then we compute the **sum of squared errors** $(SSE)$ in one of two equivalent ways: $SSE = SST - SSG = (n_1-1)s_1^2 + (n_2-1)s_2^2 + \\cdots + (n_k-1)s_k^2$ where $s_i^2$ is the sample variance (square of the standard deviation) of the residuals in group $i.$ Then the $MSE$ is the standardized form of $SSE: MSE = \\frac{1}{df_{E}}SSE.$\n\nWhen the null hypothesis is true, any differences among the sample means are only due to chance, and the $MSG$ and $MSE$ should be about equal.\nAs a test statistic for ANOVA, we examine the fraction of $MSG$ and $MSE:$\n\n$$F = \\frac{MSG}{MSE}$$\n\nThe $MSG$ represents a measure of the between-group variability,and $MSE$ measures the variability within each of the groups.\n\n::: {.important data-latex=\"\"}\n**The test statistic for three or more means is an F.**\n\nThe F statistic is a ratio of how the groups differ (MSG) as compared to how the observations within a group vary (MSE).\n\n$$F = \\frac{MSG}{MSE}$$\n\nWhen the null hypothesis is true and the conditions are met, F has an F-distribution with $df_1 = k-1$ and $df_2 = n-k.$\n\nConditions:\n\n-   independent observations, both within and across groups\\\n-   large samples and no extreme outliers\\\n:::\n\n### Variability of the statistic\n\nWe recall the exams from Section \\@ref(rand2mean) which demonstrated a two-sample randomization test for a comparison of means.\nSuppose now that the teacher had had such an extremely large class that three different exams were given: A, B, and C.\nTable \\@ref(tab:summaryStatsForThreeVersionsOfExams) and Figure \\@ref(fig:boxplotThreeVersionsOfExams) provide a summary of the data including exam C.\nAgain, we would like to investigate whether the difficulty of the exams is the same across the three exams, so the test is\n\n-   $H_0: \\mu_A = \\mu_B = \\mu_C.$ The inherent average difficulty is the same across the three exams.\n-   $H_A:$ not $H_0.$ At least one of the exams is inherently more (or less) difficult than the others.\n\n::: {.data data-latex=\"\"}\nThe [`classdata`](http://openintrostat.github.io/openintro/reference/classdata.html) data can be found in the [**openintro**](http://openintrostat.github.io/openintro) R package.\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Summary statistics of scores for each exam version.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Exam </th>\n   <th style=\"text-align:center;\"> n </th>\n   <th style=\"text-align:center;\"> Mean </th>\n   <th style=\"text-align:center;\"> SD </th>\n   <th style=\"text-align:center;\"> Min </th>\n   <th style=\"text-align:center;\"> Max </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;width: 5em; \"> A </td>\n   <td style=\"text-align:center;width: 5em; \"> 58 </td>\n   <td style=\"text-align:center;width: 5em; \"> 75.1 </td>\n   <td style=\"text-align:center;width: 5em; \"> 13.9 </td>\n   <td style=\"text-align:center;width: 5em; \"> 44 </td>\n   <td style=\"text-align:center;width: 5em; \"> 100 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 5em; \"> B </td>\n   <td style=\"text-align:center;width: 5em; \"> 55 </td>\n   <td style=\"text-align:center;width: 5em; \"> 72.0 </td>\n   <td style=\"text-align:center;width: 5em; \"> 13.8 </td>\n   <td style=\"text-align:center;width: 5em; \"> 38 </td>\n   <td style=\"text-align:center;width: 5em; \"> 100 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 5em; \"> C </td>\n   <td style=\"text-align:center;width: 5em; \"> 51 </td>\n   <td style=\"text-align:center;width: 5em; \"> 78.9 </td>\n   <td style=\"text-align:center;width: 5em; \"> 13.1 </td>\n   <td style=\"text-align:center;width: 5em; \"> 45 </td>\n   <td style=\"text-align:center;width: 5em; \"> 100 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Exam scores for students given one of three different exams.](22-inference-many-means_files/figure-html/boxplotThreeVersionsOfExams-1.png){width=90%}\n:::\n:::\n\n\nFigure \\@ref(fig:randANOVA) shows the process of randomizing the three different exams to the observed exam scores.\nIf the null hypothesis is true, then the score on each exam should represent the true student ability on that material.\nIt shouldn't matter whether they were given exam A or exam B or exam C.\nBy reallocating which student got which exam, we are able to understand how the difference in average exam scores changes due only to natural variability.\nThere is only one iteration of the randomization process in Figure \\@ref(fig:randANOVA), leading to three different randomized sample means (computed assuming the null hypothesis is true).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![The version of the test (A or B or C) is randomly allocated to the test scores, under the null assumption that the tests are equally difficult.](images/randANOVA.png){fig-alt='Four panels representing four different orientations of a toy dataset of 13 exam scores.  The first panel provides the observed data; 4 of the exams were version A and the average score was 77.25; 5 of the exams were version B and the average score was 75.8; 4 of the exams were version C and the average score was 78.5.  The observed F statistic is 0.0747.  The second panel shows the shuffled reassignment of the exam versions (4 of the scores are randomly reassigned to A, 5 of the scores are randomly reassigned to B, 4 of the scores are randomly reassigned to C).  The third panel shows which score is connected with which new reassigned version of the exam.  And the fourth panel sorts the exams so that version A exams are together, version B exams are together, and version C exams are together.  In the randomly reassigned versions, the average score for version A is 72.25, the average score for version B is 78, and the average score for version C is 75.25.  The randomized F statistic is 0.1637.' width=75%}\n:::\n:::\n\n\nIn the two-sample case, the null hypothesis was investigated using the difference in the sample means.\nHowever, as noted above, with three groups (three different exams), the comparison of the three sample means gets slightly more complicated.\nWe have already derived the F-statistic which is exactly the way to compare the averages across three or more groups!\nRecall, the F statistic is a ratio of how the groups differ (MSG) as compared to how the observations within a group vary (MSE).\n\nBuilding on Figure \\@ref(fig:randANOVA), Figure \\@ref(fig:rand3exams) shows the values of the simulated $F$ statistics over 1,000 random simulations.\nWe see that, just by chance, the F statistic can be as large as 7.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Histogram of F statistics calculated from 1,000 different randomizations of the exam type.](22-inference-many-means_files/figure-html/rand3exams-1.png){width=90%}\n:::\n:::\n\n\n### Observed statistic vs. null statistic\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Histogram of F statistics calculated from 1000 different randomizations of the exam type. The observed F statistic is given as a red vertical line 3.48.  The area to the right is more extreme than the observed value and represents the p-value.](22-inference-many-means_files/figure-html/rand3examspval-1.png){width=90%}\n:::\n:::\n\n\nUsing statistical software, we can calculate that 3.6% of the randomized F test statistics were at or above the observed test statistic of $F= 3.48.$ That is, the p-value of the test is 0.036.\nAssuming that we had set the level of discernibility to be $\\alpha = 0.05,$ the p-value is smaller than the level of discernibility which would lead us to reject the null hypothesis.\nWe claim that the difficulty level (i.e., the true average score, $\\mu)$ is different for at least one of the exams.\n\nWhile it is temping to say that exam C is harder than the other two (given the inability to differentiate between exam A and exam B in Section \\@ref(rand2mean)), we must be very careful about conclusions made using different techniques on the same data.\n\nWhen the null hypothesis is true, random variability that exists in nature produces data with p-values less than 0.05.\nHow often does that happen?\n5% of the time.\nThat is to say, if you use 20 different models applied to the same data where there is no signal (i.e., the null hypothesis is true), you are reasonably likely to to get a p-value less than 0.05 in one of the tests you run.\nThe details surrounding the ideas of this problem, called a **multiple comparisons test** or **multiple comparisons problem**, are outside the scope of this textbook, but should be something that you keep in the back of your head.\nTo best mitigate any extra type I errors, we suggest that you set up your hypotheses and testing protocol before running any analyses.\nOnce the conclusions have been reached, you should report your findings instead of running a different type of test on the same data.\n\n## Mathematical model for test for comparing many means {#sec-mathANOVA}\n\nAs seen with many of the tests and statistics from previous sections, the randomization test on the F statistic has mathematical theory to describe the distribution without using a computational approach.\n\nWe return to the baseball example from Table \\@ref(tab:mlbHRPerABSummaryTable) to demonstrate the mathematical model applied to the ANOVA setting.\n\n### Variability of the statistic\n\nThe larger the observed variability in the sample means $(MSG)$ relative to the within-group observations $(MSE)$, the larger $F$-statistic will be and the stronger the evidence against the null hypothesis.\nBecause larger $F$-statistics represent stronger evidence against the null hypothesis, we use the upper tail of the distribution to compute a p-value.\n\n::: {.important data-latex=\"\"}\n**The F statistic and the F-test.**\n\nAnalysis of variance (ANOVA) is used to test whether the mean outcome differs across two or more groups.\nANOVA uses a test statistic, the $F$-statistic, which represents a standardized ratio of variability in the sample means relative to the variability within the groups.\nIf $H_0$ is true and the model conditions are satisfied, an $F$-statistic follows an $F$ distribution with parameters $df_{1} = k - 1$ and $df_{2} = n - k.$ The upper tail of the $F$ distribution is used to represent the p-value.\n:::\n\n::: {.guidedpractice data-latex=\"\"}\nFor the baseball data, $MSG = 0.00803$ and $MSE=0.00158.$ Identify the degrees of freedom associated with MSG and MSE and verify the $F$-statistic is approximately 5.077.[^22-inference-many-means-5]\n:::\n\n[^22-inference-many-means-5]: There are $k = 3$ groups, so $df_{G} = k - 1 = 2.$ There are $n = n_1 + n_2 + n_3 = 429$ total observations, so $df_{E} = n - k = 426.$ Then the $F$-statistic is computed as the ratio of $MSG$ and $MSE:$ $F = \\frac{MSG}{MSE} = \\frac{0.00803}{0.00158} = 5.082 \\approx 5.077.$ $(F = 5.077$ was computed by using values for $MSG$ and $MSE$ that were not rounded.)\n\n### Observed statistic vs. null statistics\n\nWe can use the $F$-statistic to evaluate the hypotheses in what is called an F-test.\nA p-value can be computed from the $F$ statistic using an $F$ distribution, which has two associated parameters: $df_{1}$ and $df_{2}.$ For the $F$-statistic in ANOVA, $df_{1} = df_{G}$ and $df_{2} = df_{E}.$ An $F$ distribution with 2 and 426 degrees of freedom, corresponding to the $F$ statistic for the baseball hypothesis test, is shown in Figure \\@ref(fig:fDist2And423Shaded).\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![An $F$ distribution with $df_1=2$ and $df_2=426.$](22-inference-many-means_files/figure-html/fDist2And423Shaded-1.png){width=90%}\n:::\n:::\n\n\n::: {.workedexample data-latex=\"\"}\nThe p-value corresponding to the shaded area in Figure \\@ref(fig:fDist2And423Shaded) is equal to about 0.0066.\nDoes this provide strong evidence against the null hypothesis?\n\n------------------------------------------------------------------------\n\nThe p-value is smaller than 0.05, indicating the evidence is strong enough to reject the null hypothesis at a discernibility level of 0.05.\nThat is, the data provide strong evidence that the average on-base percentage varies by player's primary field position.\n:::\n\nNote that the small p-value indicates that there is a notable difference between the mean batting averages of the different positions.\nHowever, the ANOVA test does not provide a mechanism for knowing *which* group is driving the differences.\nIf we move forward with all possible two mean comparisons, we run the risk of a high type I error rate.\nAs we saw at the end of Section \\@ref(randANOVA), the follow-up questions surrounding individual group comparisons is called a problem of **multiple comparisons**\\index{multiple comparisons} and is outside the scope of this text.\nWe encourage you to learn more about multiple comparisons, however, so that additional comparisons, after you have rejected the null hypothesis in an ANOVA test, do not lead to undue false positive conclusions.\n\n\n\n\n\n### Reading an ANOVA table from software\n\nThe calculations required to perform an ANOVA by hand are tedious and prone to human error.\nFor these reasons, it is common to use statistical software to calculate the $F$-statistic and p-value.\n\nAn ANOVA can be summarized in a table very similar to that of a regression summary, which we saw in Chapters \\@ref(model-slr) and \\@ref(model-mlr).\nTable \\@ref(tab:anovaSummaryTableForOBPAgainstPosition) shows an ANOVA summary to test whether the mean of on-base percentage varies by player positions in the MLB.\nMany of these values should look familiar; in particular, the $F$-statistic and p-value can be retrieved from the last two columns.\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>ANOVA summary for testing whether the average on-base percentage differs across player positions.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> df </th>\n   <th style=\"text-align:right;\"> sumsq </th>\n   <th style=\"text-align:right;\"> meansq </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;width: 10em; font-family: monospace;\"> position </td>\n   <td style=\"text-align:right;width: 5em; \"> 2 </td>\n   <td style=\"text-align:right;width: 5em; \"> 0.0161 </td>\n   <td style=\"text-align:right;width: 5em; \"> 0.0080 </td>\n   <td style=\"text-align:right;width: 5em; \"> 5.08 </td>\n   <td style=\"text-align:right;width: 5em; \"> 0.0066 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 10em; font-family: monospace;\"> Residuals </td>\n   <td style=\"text-align:right;width: 5em; \"> 426 </td>\n   <td style=\"text-align:right;width: 5em; \"> 0.6740 </td>\n   <td style=\"text-align:right;width: 5em; \"> 0.0016 </td>\n   <td style=\"text-align:right;width: 5em; \">  </td>\n   <td style=\"text-align:right;width: 5em; \">  </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n### Conditions for an ANOVA analysis\n\nThere are three conditions we must check for an ANOVA analysis: all observations must be independent, the data in each group must be nearly normal, and the variance within each group must be approximately equal.\n\n-   **Independence.** If the data are a simple random sample, this condition can be assumed to be satisfied.\n    For processes and experiments, carefully consider whether the data may be independent (e.g., no pairing).\n    For example, in the MLB data, the data were not sampled.\n    However, there are not obvious reasons why independence would not hold for most or all observations.\n\n-   **Approximately normal.** As with one- and two-sample testing for means, the normality assumption is especially important when the sample size is quite small when it is ironically difficult to check for non-normality.\n    A histogram of the observations from each group is shown in Figure \\@ref(fig:mlbANOVADiagNormalityGroups).\n    Since each of the groups we are considering have relatively large sample sizes, what we are looking for are major outliers.\n    None are apparent, so this conditions is reasonably met.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Histograms of OBP for each field position.](22-inference-many-means_files/figure-html/mlbANOVADiagNormalityGroups-1.png){width=90%}\n:::\n:::\n\n\n-   **Constant variance.** The last assumption is that the variance in the groups is about equal from one group to the next. This assumption can be checked by examining a side-by-side box plot of the outcomes across the groups, as in Figure \\@ref(fig:mlbANOVABoxPlot). In this case, the variability is similar in the four groups but not identical. We see in Table \\@ref(tab:mlbHRPerABSummaryTable) that the standard deviation does not vary much from one group to the next.\n\n::: {.important data-latex=\"\"}\n**Diagnostics for an ANOVA analysis.**\n\nIndependence is always important to an ANOVA analysis.\nThe normality condition is very important when the sample sizes for each group are relatively small.\nThe constant variance condition is especially important when the sample sizes differ between groups.\n:::\n\n\\clearpage\n\n## Chapter review {#sec-chp22-review}\n\n### Summary\n\nIn this chapter we have provided both the randomization test and the mathematical model appropriate for addressing questions of equality of means across two or more groups.\nNote that there were important technical conditions required for confirming that the F distribution appropriately modeled the ANOVA test statistic.\nAlso, you may have noticed that there was no discussion of creating confidence intervals.\nThat is because the ANOVA statistic does not have a direct analogue parameter to estimate.\nIf there is interest in comparisons of mean differences (across each set of two groups), then the methods from Chapter \\@ref(inference-two-means) comparing two independent means should be applied.\n\n### Terms\n\nWe introduced the following terms in the chapter.\nIf you're not sure what some of these terms mean, we recommend you go back in the text and review their definitions.\nWe are purposefully presenting them in alphabetical order, instead of in order of appearance, so they will be a little more challenging to locate.\nHowever, you should be able to easily spot them as **bolded text**.\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> analysis of variance </td>\n   <td style=\"text-align:left;\"> F-test </td>\n   <td style=\"text-align:left;\"> sum of squared error (SSE) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ANOVA </td>\n   <td style=\"text-align:left;\"> mean square between groups (MSG) </td>\n   <td style=\"text-align:left;\"> sum of squares between groups (SSG) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> data fishing </td>\n   <td style=\"text-align:left;\"> mean square error (MSE) </td>\n   <td style=\"text-align:left;\"> sum of squares total (SST) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> data snooping </td>\n   <td style=\"text-align:left;\"> multiple comparisons </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> degrees of freedom </td>\n   <td style=\"text-align:left;\"> prosecutor's fallacy </td>\n   <td style=\"text-align:left;\">  </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\\clearpage\n\n## Exercises {#sec-chp22-exercises}\n\nAnswers to odd-numbered exercises can be found in [Appendix -@sec-exercise-solutions-22].\n\n::: {.exercises data-latex=\"\"}\n1.  **Fill in the blank.** When doing an ANOVA, you observe large differences in means between groups.\n    Within the ANOVA framework, this would most likely be interpreted as evidence strongly favoring the \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ hypothesis.\n\n2.  **Which test?** We would like to test if students who are in the social sciences, natural sciences, arts and humanities, and other fields spend the same amount of time, on average, studying for a course.\n    What type of test should we use?\n    Explain your reasoning.\n\n3.  **Cuckoo bird egg lengths, randomize once.** Cuckoo birds lay their eggs in other birds' nests, making them known as brood parasites.\n    One question relates to whether the size of the cuckoo egg differs depending on the species of the host bird.[^_22-ex-inference-many-means-1]\n    [@Latter:1902]\n\n    Consider the following plots, one represents the original data, the second represents data where the host species has been randomly assigned to the egg length.\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    ![](22-inference-many-means_files/figure-html/unnamed-chunk-22-1.png){width=90%}\n    :::\n    :::\n\n    a.  Consider the average length of the eggs for each species.\n        Is the average length for the original data: more variable, less variable, or about the same as the randomized species?\n        Describe what you see in the plots.\n\n    b.  Consider the standard deviation of the lengths of the eggs within each species.\n        Is the within species standard deviation of the length for the original data: bigger, smaller, or about the same as the randomized species?\n\n    c.  Recall that the F statistic's numerator measures how much the groups vary (MSG) with the denominator measuring how much the within species values vary (MSE), which of the plots above would have a larger F statistic, the original data or the randomized data?\n        Explain.\n\n4.  **Cuckoo bird egg lengths, randomization test.** Cuckoo birds lay their eggs in other birds' nests, making them known as brood parasites.\n    One question relates to whether the size of the cuckoo egg differs depending on the species of the host bird.[^_22-ex-inference-many-means-2]\n    [@Latter:1902]\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    ![](22-inference-many-means_files/figure-html/unnamed-chunk-23-1.png){width=90%}\n    :::\n    :::\n\n    Using the randomization distribution of the F statistic (host species randomized to egg length), conduct a hypothesis test to evaluate if there is a difference, in the population, between the average egg lengths for different host bird species.\n    Make sure to state your hypotheses clearly and interpret your results in context of the data.\n\n5.  **Chicken diet and weight, many groups.** An experiment was conducted to measure and compare the effectiveness of various feed supplements on the growth rate of chickens.\n    Newly hatched chicks were randomly allocated into six groups, and each group was given a different feed supplement.\n    Sample statistics and a visualization of the observed data are shown below.\n    [@data:chickwts]\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    ![](22-inference-many-means_files/figure-html/unnamed-chunk-24-1.png){width=70%}\n    :::\n    \n    ::: {.cell-output-display}\n    `````{=html}\n    <table class=\"table table-striped table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n     <thead>\n      <tr>\n       <th style=\"text-align:left;\"> Feed type </th>\n       <th style=\"text-align:center;\"> Mean </th>\n       <th style=\"text-align:center;\"> SD </th>\n       <th style=\"text-align:center;\"> n </th>\n      </tr>\n     </thead>\n    <tbody>\n      <tr>\n       <td style=\"text-align:left;\"> casein </td>\n       <td style=\"text-align:center;\"> 323.58 </td>\n       <td style=\"text-align:center;\"> 64.43 </td>\n       <td style=\"text-align:center;\"> 12 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;\"> horsebean </td>\n       <td style=\"text-align:center;\"> 160.20 </td>\n       <td style=\"text-align:center;\"> 38.63 </td>\n       <td style=\"text-align:center;\"> 10 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;\"> linseed </td>\n       <td style=\"text-align:center;\"> 218.75 </td>\n       <td style=\"text-align:center;\"> 52.24 </td>\n       <td style=\"text-align:center;\"> 12 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;\"> meatmeal </td>\n       <td style=\"text-align:center;\"> 276.91 </td>\n       <td style=\"text-align:center;\"> 64.90 </td>\n       <td style=\"text-align:center;\"> 11 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;\"> soybean </td>\n       <td style=\"text-align:center;\"> 246.43 </td>\n       <td style=\"text-align:center;\"> 54.13 </td>\n       <td style=\"text-align:center;\"> 14 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;\"> sunflower </td>\n       <td style=\"text-align:center;\"> 328.92 </td>\n       <td style=\"text-align:center;\"> 48.84 </td>\n       <td style=\"text-align:center;\"> 12 </td>\n      </tr>\n    </tbody>\n    </table>\n    \n    `````\n    :::\n    :::\n\n    ::: {.content-hidden unless-format=\"pdf\"} \n    *See next page for the rest of the exercise.* \n    :::\n\n    \\clearpage\n\n    The ANOVA output below can be used to test for differences between the average weights of chicks on different diets.\n    Conduct a hypothesis test to determine if these data provide convincing evidence that the average weight of chicks varies across some (or all) groups.\n    Make sure to check relevant conditions.\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    `````{=html}\n    <table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n     <thead>\n      <tr>\n       <th style=\"text-align:left;\"> term </th>\n       <th style=\"text-align:right;\"> df </th>\n       <th style=\"text-align:right;\"> sumsq </th>\n       <th style=\"text-align:right;\"> meansq </th>\n       <th style=\"text-align:right;\"> statistic </th>\n       <th style=\"text-align:right;\"> p.value </th>\n      </tr>\n     </thead>\n    <tbody>\n      <tr>\n       <td style=\"text-align:left;width: 5em; font-family: monospace;\"> feed </td>\n       <td style=\"text-align:right;width: 5em; \"> 5 </td>\n       <td style=\"text-align:right;width: 5em; \"> 231,129 </td>\n       <td style=\"text-align:right;width: 5em; \"> 46,226 </td>\n       <td style=\"text-align:right;width: 5em; \"> 15.4 </td>\n       <td style=\"text-align:right;width: 5em; \"> &lt;0.0001 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 5em; font-family: monospace;\"> Residuals </td>\n       <td style=\"text-align:right;width: 5em; \"> 65 </td>\n       <td style=\"text-align:right;width: 5em; \"> 195,556 </td>\n       <td style=\"text-align:right;width: 5em; \"> 3,009 </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n      </tr>\n    </tbody>\n    </table>\n    \n    `````\n    :::\n    :::\n\n6.  **Teaching descriptive statistics.** A study compared five different methods for teaching descriptive statistics.\n    The five methods were traditional lecture and discussion, programmed textbook instruction, programmed text with lectures, computer instruction, and computer instruction with lectures.\n    45 students were randomly assigned, 9 to each method.\n    After completing the course, students took a 1-hour exam.\n\n    a.  What are the hypotheses for evaluating if the average test scores are different for the different teaching methods?\n\n    b.  What are the degrees of freedom associated with the $F$-test for evaluating these hypotheses?\n\n    c.  Suppose the p-value for this test is 0.0168.\n        What is the conclusion?\n\n7.  **Coffee, depression, and physical activity.** Caffeine is the world's most widely used stimulant, with approximately 80% consumed in the form of coffee.\n    Participants in a study investigating the relationship between coffee consumption and exercise were asked to report the number of hours they spent per week on moderate (e.g., brisk walking) and vigorous (e.g., strenuous sports and jogging) exercise.\n    Based on these data the researchers estimated the total hours of metabolic equivalent tasks (MET) per week, a value always greater than 0.\n    The table below gives summary statistics of MET for women in this study based on the amount of coffee consumed.\n    [@Lucas:2011]\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    `````{=html}\n    <table class=\"table table-striped table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n     <thead>\n    <tr>\n    <th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n    <th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"5\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Caffeinated coffee consumption</div></th>\n    </tr>\n      <tr>\n       <th style=\"text-align:left;\">   </th>\n       <th style=\"text-align:right;\"> 1 cup / week or fewer </th>\n       <th style=\"text-align:right;\"> 2-6 cups / week </th>\n       <th style=\"text-align:right;\"> 1 cups / day </th>\n       <th style=\"text-align:right;\"> 2-3 cups / day </th>\n       <th style=\"text-align:right;\"> 4 cups / day or more </th>\n      </tr>\n     </thead>\n    <tbody>\n      <tr>\n       <td style=\"text-align:left;width: 3em; \"> Mean </td>\n       <td style=\"text-align:right;width: 3em; \"> 18.7 </td>\n       <td style=\"text-align:right;width: 3em; \"> 19.6 </td>\n       <td style=\"text-align:right;width: 3em; \"> 19.3 </td>\n       <td style=\"text-align:right;width: 3em; \"> 18.9 </td>\n       <td style=\"text-align:right;width: 3em; \"> 17.5 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 3em; \"> SD </td>\n       <td style=\"text-align:right;width: 3em; \"> 21.1 </td>\n       <td style=\"text-align:right;width: 3em; \"> 25.5 </td>\n       <td style=\"text-align:right;width: 3em; \"> 22.5 </td>\n       <td style=\"text-align:right;width: 3em; \"> 22.0 </td>\n       <td style=\"text-align:right;width: 3em; \"> 22.0 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 3em; \"> n </td>\n       <td style=\"text-align:right;width: 3em; \"> 12,215.0 </td>\n       <td style=\"text-align:right;width: 3em; \"> 6,617.0 </td>\n       <td style=\"text-align:right;width: 3em; \"> 17,234.0 </td>\n       <td style=\"text-align:right;width: 3em; \"> 12,290.0 </td>\n       <td style=\"text-align:right;width: 3em; \"> 2,383.0 </td>\n      </tr>\n    </tbody>\n    </table>\n    \n    `````\n    :::\n    :::\n\n    a.  Write the hypotheses for evaluating if the average physical activity level varies among the different levels of coffee consumption.\n\n    b.  Check conditions and describe any assumptions you must make to proceed with the test.\n\n    c.  Below is the output associated with this test.\n        What is the conclusion of the test?\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    `````{=html}\n    <table class=\"table table-striped table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n     <thead>\n      <tr>\n       <th style=\"text-align:left;\">   </th>\n       <th style=\"text-align:right;\"> df </th>\n       <th style=\"text-align:right;\"> sumsq </th>\n       <th style=\"text-align:right;\"> meansq </th>\n       <th style=\"text-align:right;\"> statistic </th>\n       <th style=\"text-align:right;\"> p.value </th>\n      </tr>\n     </thead>\n    <tbody>\n      <tr>\n       <td style=\"text-align:left;width: 5em; \"> cofee </td>\n       <td style=\"text-align:right;width: 5em; \"> 4 </td>\n       <td style=\"text-align:right;width: 5em; \"> 10,508 </td>\n       <td style=\"text-align:right;width: 5em; \"> 2,627 </td>\n       <td style=\"text-align:right;width: 5em; \"> 5.2 </td>\n       <td style=\"text-align:right;width: 5em; \"> 0 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 5em; \"> Residuals </td>\n       <td style=\"text-align:right;width: 5em; \"> 50,734 </td>\n       <td style=\"text-align:right;width: 5em; \"> 25,564,819 </td>\n       <td style=\"text-align:right;width: 5em; \"> 504 </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 5em; \"> Total </td>\n       <td style=\"text-align:right;width: 5em; \"> 50,738 </td>\n       <td style=\"text-align:right;width: 5em; \"> 25,575,327 </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n      </tr>\n    </tbody>\n    </table>\n    \n    `````\n    :::\n    :::\n\n    \\clearpage\n\n8.  **Student performance across discussion sections.** A professor who teaches a large introductory statistics class (197 students) with eight discussion sections would like to test if student performance differs by discussion section, where each discussion section has a different teaching assistant.\n    The summary table below shows the average final exam score for each discussion section as well as the standard deviation of scores and the number of students in each section.\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    `````{=html}\n    <table class=\"table table-striped table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n     <thead>\n      <tr>\n       <th style=\"text-align:left;\">   </th>\n       <th style=\"text-align:right;\"> Sec 1 </th>\n       <th style=\"text-align:right;\"> Sec 2 </th>\n       <th style=\"text-align:right;\"> Sec 3 </th>\n       <th style=\"text-align:right;\"> Sec 4 </th>\n       <th style=\"text-align:right;\"> Sec 5 </th>\n       <th style=\"text-align:right;\"> Sec 6 </th>\n       <th style=\"text-align:right;\"> Sec 7 </th>\n       <th style=\"text-align:right;\"> Sec 8 </th>\n      </tr>\n     </thead>\n    <tbody>\n      <tr>\n       <td style=\"text-align:left;width: 4em; \"> Mean </td>\n       <td style=\"text-align:right;width: 4em; \"> 92.94 </td>\n       <td style=\"text-align:right;width: 4em; \"> 91.11 </td>\n       <td style=\"text-align:right;width: 4em; \"> 91.80 </td>\n       <td style=\"text-align:right;width: 4em; \"> 92.45 </td>\n       <td style=\"text-align:right;width: 4em; \"> 89.30 </td>\n       <td style=\"text-align:right;width: 4em; \"> 88.30 </td>\n       <td style=\"text-align:right;width: 4em; \"> 90.12 </td>\n       <td style=\"text-align:right;width: 4em; \"> 93.35 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 4em; \"> SD </td>\n       <td style=\"text-align:right;width: 4em; \"> 4.21 </td>\n       <td style=\"text-align:right;width: 4em; \"> 5.58 </td>\n       <td style=\"text-align:right;width: 4em; \"> 3.43 </td>\n       <td style=\"text-align:right;width: 4em; \"> 5.92 </td>\n       <td style=\"text-align:right;width: 4em; \"> 9.32 </td>\n       <td style=\"text-align:right;width: 4em; \"> 7.27 </td>\n       <td style=\"text-align:right;width: 4em; \"> 6.93 </td>\n       <td style=\"text-align:right;width: 4em; \"> 4.57 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 4em; \"> n </td>\n       <td style=\"text-align:right;width: 4em; \"> 33.00 </td>\n       <td style=\"text-align:right;width: 4em; \"> 19.00 </td>\n       <td style=\"text-align:right;width: 4em; \"> 10.00 </td>\n       <td style=\"text-align:right;width: 4em; \"> 29.00 </td>\n       <td style=\"text-align:right;width: 4em; \"> 33.00 </td>\n       <td style=\"text-align:right;width: 4em; \"> 10.00 </td>\n       <td style=\"text-align:right;width: 4em; \"> 32.00 </td>\n       <td style=\"text-align:right;width: 4em; \"> 31.00 </td>\n      </tr>\n    </tbody>\n    </table>\n    \n    `````\n    :::\n    :::\n\n    The ANOVA output below can be used to test for differences between the average scores from the different discussion sections.\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    `````{=html}\n    <table class=\"table table-striped table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n     <thead>\n      <tr>\n       <th style=\"text-align:left;\">   </th>\n       <th style=\"text-align:right;\"> df </th>\n       <th style=\"text-align:right;\"> sumsq </th>\n       <th style=\"text-align:right;\"> meansq </th>\n       <th style=\"text-align:right;\"> statistic </th>\n       <th style=\"text-align:right;\"> p.value </th>\n      </tr>\n     </thead>\n    <tbody>\n      <tr>\n       <td style=\"text-align:left;width: 5em; \"> section </td>\n       <td style=\"text-align:right;width: 5em; \"> 7 </td>\n       <td style=\"text-align:right;width: 5em; \"> 525 </td>\n       <td style=\"text-align:right;width: 5em; \"> 75.0 </td>\n       <td style=\"text-align:right;width: 5em; \"> 1.87 </td>\n       <td style=\"text-align:right;width: 5em; \"> 0.077 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 5em; \"> Residuals </td>\n       <td style=\"text-align:right;width: 5em; \"> 189 </td>\n       <td style=\"text-align:right;width: 5em; \"> 7,584 </td>\n       <td style=\"text-align:right;width: 5em; \"> 40.1 </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 5em; \"> Total </td>\n       <td style=\"text-align:right;width: 5em; \"> 196 </td>\n       <td style=\"text-align:right;width: 5em; \"> 8,109 </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n      </tr>\n    </tbody>\n    </table>\n    \n    `````\n    :::\n    :::\n\n    Conduct a hypothesis test to determine if these data provide convincing evidence that the average score varies across some (or all) groups.\n    Check conditions and describe any assumptions you must make to proceed with the test.\n\n9.  **GPA and major.** Undergraduate students taking an introductory statistics course at Duke University conducted a survey about GPA and major.\n    The side-by-side box plots show the distribution of GPA among three groups of majors.\n    Also provided is the ANOVA output.\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    ![](22-inference-many-means_files/figure-html/unnamed-chunk-30-1.png){width=90%}\n    :::\n    \n    ::: {.cell-output-display}\n    `````{=html}\n    <table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n     <thead>\n      <tr>\n       <th style=\"text-align:left;\"> term </th>\n       <th style=\"text-align:right;\"> df </th>\n       <th style=\"text-align:right;\"> sumsq </th>\n       <th style=\"text-align:right;\"> meansq </th>\n       <th style=\"text-align:right;\"> statistic </th>\n       <th style=\"text-align:right;\"> p.value </th>\n      </tr>\n     </thead>\n    <tbody>\n      <tr>\n       <td style=\"text-align:left;width: 4em; font-family: monospace;\"> major </td>\n       <td style=\"text-align:right;width: 4em; \"> 2 </td>\n       <td style=\"text-align:right;width: 4em; \"> 0.03 </td>\n       <td style=\"text-align:right;width: 4em; \"> 0.02 </td>\n       <td style=\"text-align:right;width: 4em; \"> 0.21 </td>\n       <td style=\"text-align:right;width: 4em; \"> 0.81 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 4em; font-family: monospace;\"> Residuals </td>\n       <td style=\"text-align:right;width: 4em; \"> 195 </td>\n       <td style=\"text-align:right;width: 4em; \"> 15.77 </td>\n       <td style=\"text-align:right;width: 4em; \"> 0.08 </td>\n       <td style=\"text-align:right;width: 4em; \">  </td>\n       <td style=\"text-align:right;width: 4em; \">  </td>\n      </tr>\n    </tbody>\n    </table>\n    \n    `````\n    :::\n    :::\n\n    a.  Write the hypotheses for testing for a difference between average GPA across majors.\n\n    b.  What is the conclusion of the hypothesis test?\n\n    c.  How many students answered these questions on the survey, i.e. what is the sample size?\n\n    \\clearpage\n\n10. **Work hours and education.** The General Social Survey collects data on demographics, education, and work, among many other characteristics of US residents.\n    [@data:gss:2010] Using ANOVA, we can consider educational attainment levels for all 1,172 respondents at once.\n    Below are the distributions of hours worked by educational attainment and relevant summary statistics that will be helpful in carrying out this analysis.\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    `````{=html}\n    <table class=\"table table-striped table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n     <thead>\n      <tr>\n       <th style=\"text-align:left;\"> Educational attainment </th>\n       <th style=\"text-align:right;\"> Mean </th>\n       <th style=\"text-align:right;\"> SD </th>\n       <th style=\"text-align:right;\"> n </th>\n      </tr>\n     </thead>\n    <tbody>\n      <tr>\n       <td style=\"text-align:left;width: 12em; \"> Lt High School </td>\n       <td style=\"text-align:right;width: 5em; \"> 38.7 </td>\n       <td style=\"text-align:right;width: 5em; \"> 15.8 </td>\n       <td style=\"text-align:right;width: 5em; \"> 121 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 12em; \"> High School </td>\n       <td style=\"text-align:right;width: 5em; \"> 39.6 </td>\n       <td style=\"text-align:right;width: 5em; \"> 15.0 </td>\n       <td style=\"text-align:right;width: 5em; \"> 546 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 12em; \"> Junior College </td>\n       <td style=\"text-align:right;width: 5em; \"> 41.4 </td>\n       <td style=\"text-align:right;width: 5em; \"> 18.1 </td>\n       <td style=\"text-align:right;width: 5em; \"> 97 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 12em; \"> Bachelor </td>\n       <td style=\"text-align:right;width: 5em; \"> 42.5 </td>\n       <td style=\"text-align:right;width: 5em; \"> 13.6 </td>\n       <td style=\"text-align:right;width: 5em; \"> 253 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 12em; \"> Graduate </td>\n       <td style=\"text-align:right;width: 5em; \"> 40.8 </td>\n       <td style=\"text-align:right;width: 5em; \"> 15.5 </td>\n       <td style=\"text-align:right;width: 5em; \"> 155 </td>\n      </tr>\n    </tbody>\n    </table>\n    \n    `````\n    :::\n    \n    ::: {.cell-output-display}\n    ![](22-inference-many-means_files/figure-html/unnamed-chunk-31-1.png){width=100%}\n    :::\n    :::\n\n    a.  Write hypotheses for evaluating whether the average number of hours worked varies across the five groups.\n\n    b.  Check conditions and describe any assumptions you must make to proceed with the test.\n\n    c.  Below is the output associated with this test.\n        What is the conclusion of the test?\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    `````{=html}\n    <table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n     <thead>\n      <tr>\n       <th style=\"text-align:left;\"> term </th>\n       <th style=\"text-align:right;\"> df </th>\n       <th style=\"text-align:right;\"> sumsq </th>\n       <th style=\"text-align:right;\"> meansq </th>\n       <th style=\"text-align:right;\"> statistic </th>\n       <th style=\"text-align:right;\"> p.value </th>\n      </tr>\n     </thead>\n    <tbody>\n      <tr>\n       <td style=\"text-align:left;width: 8em; font-family: monospace;\"> degree </td>\n       <td style=\"text-align:right;width: 5em; \"> 4 </td>\n       <td style=\"text-align:right;width: 5em; \"> 2,006 </td>\n       <td style=\"text-align:right;width: 5em; \"> 502 </td>\n       <td style=\"text-align:right;width: 5em; \"> 2.19 </td>\n       <td style=\"text-align:right;width: 5em; \"> 0.07 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 8em; font-family: monospace;\"> Residuals </td>\n       <td style=\"text-align:right;width: 5em; \"> 1,167 </td>\n       <td style=\"text-align:right;width: 5em; \"> 267,382 </td>\n       <td style=\"text-align:right;width: 5em; \"> 229 </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n       <td style=\"text-align:right;width: 5em; \">  </td>\n      </tr>\n    </tbody>\n    </table>\n    \n    `````\n    :::\n    :::\n\n    \\clearpage\n\n11. **True / False: ANOVA, I.** Determine if the following statements are true or false in ANOVA, and explain your reasoning for statements you identify as false.\n\n    a.  As the number of groups increases, the modified discernibility level for pairwise tests increases as well.\n\n    b.  As the total sample size increases, the degrees of freedom for the residuals increases as well.\n\n    c.  The constant variance condition can be somewhat relaxed when the sample sizes are relatively consistent across groups.\n\n    d.  The independence assumption can be relaxed when the total sample size is large.\n\n12. **True / False: ANOVA, II.** Determine if the following statements are true or false, and explain your reasoning for statements you identify as false.\n\n    If the null hypothesis that the means of four groups are all the same is rejected using ANOVA at a 5% discernibility level, then...\n\n    a.  we can then conclude that all the means are different from one another.\n\n    b.  the standardized variability between groups is higher than the standardized variability within groups.\n\n    c.  the pairwise analysis will identify at least one pair of means that are discernibly different.\n\n    d.  the appropriate $\\alpha$ to be used in pairwise comparisons is 0.05 / 4 = 0.0125 since there are four groups.\n\n13. **Matching observed data with randomized F statistics.** Consider the following two datasets.\n    The response variable is the `score` and the explanatory variable is whether the individual is in one of four groups.\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    ![](22-inference-many-means_files/figure-html/unnamed-chunk-33-1.png){width=100%}\n    :::\n    :::\n\n    The randomizations (randomly assigning group to the score, calculating a randomization F statistic) were done 1000 times for each of Dataset A and B.\n    The red line on each plot indicates the observed F statistic for the original (unrandomized) data.\n\n    a.  Does the randomization distribution on the left correspond to Dataset A or B?\n        Explain.\n\n    b.  Does the randomization distribution on the right correspond to Dataset A or B?\n        Explain.\n\n    \\clearpage\n\n14. **Child care hours.** The China Health and Nutrition Survey aims to examine the effects of the health, nutrition, and family planning policies and programs implemented by national and local governments.\n    [@data:china] It, for example, collects information on number of hours Chinese parents spend taking care of their children under age 6.\n    The side-by-side box plots below show the distribution of this variable by educational attainment of the parent.\n    Also provided below is the ANOVA output for comparing average hours across educational attainment categories.\n\n    ::: {.cell}\n    ::: {.cell-output-display}\n    ![](22-inference-many-means_files/figure-html/unnamed-chunk-34-1.png){width=90%}\n    :::\n    \n    ::: {.cell-output-display}\n    `````{=html}\n    <table class=\"table table-striped table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n     <thead>\n      <tr>\n       <th style=\"text-align:left;\"> term </th>\n       <th style=\"text-align:right;\"> df </th>\n       <th style=\"text-align:right;\"> sumsq </th>\n       <th style=\"text-align:right;\"> meansq </th>\n       <th style=\"text-align:right;\"> statistic </th>\n       <th style=\"text-align:right;\"> p.value </th>\n      </tr>\n     </thead>\n    <tbody>\n      <tr>\n       <td style=\"text-align:left;width: 4em; font-family: monospace;\"> edu </td>\n       <td style=\"text-align:right;width: 4em; \"> 4 </td>\n       <td style=\"text-align:right;width: 4em; \"> 4,142 </td>\n       <td style=\"text-align:right;width: 4em; \"> 1,036 </td>\n       <td style=\"text-align:right;width: 4em; \"> 1.26 </td>\n       <td style=\"text-align:right;width: 4em; \"> 0.28 </td>\n      </tr>\n      <tr>\n       <td style=\"text-align:left;width: 4em; font-family: monospace;\"> Residuals </td>\n       <td style=\"text-align:right;width: 4em; \"> 794 </td>\n       <td style=\"text-align:right;width: 4em; \"> 653,048 </td>\n       <td style=\"text-align:right;width: 4em; \"> 822 </td>\n       <td style=\"text-align:right;width: 4em; \">  </td>\n       <td style=\"text-align:right;width: 4em; \">  </td>\n      </tr>\n    </tbody>\n    </table>\n    \n    `````\n    :::\n    :::\n\n    a.  Write the hypotheses for testing for a difference between the average number of hours spent on child care across educational attainment levels.\n\n    b.  What is the conclusion of the hypothesis test?\n\n[^_22-ex-inference-many-means-1]: The [`Cuckoo`](https://rdrr.io/cran/Stat2Data/man/Cuckoo.html) data used in this exercise can be found in the [**Stat2Data**](https://cran.r-project.org/web/packages/Stat2Data/index.html) R package.\n\n[^_22-ex-inference-many-means-2]: The data [`Cuckoo`](https://rdrr.io/cran/Stat2Data/man/Cuckoo.html) used in this exercise can be found in the [**Stat2Data**](https://cran.r-project.org/web/packages/Stat2Data/index.html) R package.\n\n\n:::\n",
    "supporting": [
      "22-inference-many-means_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n<link href=\"site_libs/bsTable-3.3.7/bootstrapTable.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/bsTable-3.3.7/bootstrapTable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}